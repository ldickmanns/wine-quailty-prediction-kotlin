{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066fcc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%use kotlin-dl\n",
    "%use krangl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc50d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.jetbrains.kotlinx.dl.api.core.history.EpochTrainingEvent\n",
    "import org.jetbrains.kotlinx.dl.api.core.history.TrainingHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7724c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun normalize(df: DataFrame): DataFrame {\n",
    "    val normalizedCols = mutableListOf<DataCol>()\n",
    "    for (col in df.cols) {\n",
    "        val min = col.min()!!\n",
    "        val max = col.max()!!\n",
    "        val normalized = (col - min) / (max - min)\n",
    "        normalizedCols.add(normalized)\n",
    "    }\n",
    "    val normalizedDF = dataFrameOf(*normalizedCols.toTypedArray())\n",
    "    normalizedDF.setNames(*df.names.toTypedArray())\n",
    "    return normalizedDF\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca1b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun getXy(\n",
    "    df: DataFrame, \n",
    "    label: String = \"quality\"\n",
    "): Pair<Array<FloatArray>, FloatArray> {\n",
    "    val features = df.remove(label)\n",
    "    val nFeatures = features.ncol\n",
    "    val normalizedFeatures = normalize(features)\n",
    "    val columnsArray = normalizedFeatures.toFloatMatrix()\n",
    "    \n",
    "    val X = Array(features.nrow) { FloatArray(nFeatures) }\n",
    "\n",
    "    for (col in 0 until nFeatures) {\n",
    "        for (row in 0 until df.nrow) {\n",
    "            X[row][col] = columnsArray[col][row]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    val labels = df.get(label).toDoubles().filterNotNull().map { it.toFloat() }\n",
    "    \n",
    "    val y = labels.toFloatArray()\n",
    "    return Pair(X, y)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a8afc82-d8c5-406b-a4a6-cb617ec2f392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><table><tr><th style=\"text-align:left\">fixed acidity</th><th style=\"text-align:left\">volatile acidity</th><th style=\"text-align:left\">citric acid</th><th style=\"text-align:left\">residual sugar</th><th style=\"text-align:left\">chlorides</th><th style=\"text-align:left\">free sulfur dioxide</th><th style=\"text-align:left\">total sulfur dioxide</th><th style=\"text-align:left\">density</th><th style=\"text-align:left\">pH</th><th style=\"text-align:left\">sulphates</th><th style=\"text-align:left\">alcohol</th><th style=\"text-align:left\">quality</th></tr><tr><td style=\"text-align:left\" title=\"7.3\">7.3</td><td style=\"text-align:left\" title=\"0.32\">0.32</td><td style=\"text-align:left\" title=\"0.35\">0.35</td><td style=\"text-align:left\" title=\"1.4\">1.4</td><td style=\"text-align:left\" title=\"0.05\">0.05</td><td style=\"text-align:left\" title=\"8.0\">8.0</td><td style=\"text-align:left\" title=\"163.0\">163.0</td><td style=\"text-align:left\" title=\"0.99244\">0.99244</td><td style=\"text-align:left\" title=\"3.24\">3.24</td><td style=\"text-align:left\" title=\"0.42\">0.42</td><td style=\"text-align:left\" title=\"10.7\">10.7</td><td style=\"text-align:left\" title=\"5\">5</td></tr><tr><td style=\"text-align:left\" title=\"7.0\">7.0</td><td style=\"text-align:left\" title=\"0.31\">0.31</td><td style=\"text-align:left\" title=\"0.26\">0.26</td><td style=\"text-align:left\" title=\"7.4\">7.4</td><td style=\"text-align:left\" title=\"0.069\">0.069</td><td style=\"text-align:left\" title=\"28.0\">28.0</td><td style=\"text-align:left\" title=\"160.0\">160.0</td><td style=\"text-align:left\" title=\"0.9954\">0.9954</td><td style=\"text-align:left\" title=\"3.13\">3.13</td><td style=\"text-align:left\" title=\"0.46\">0.46</td><td style=\"text-align:left\" title=\"9.8\">9.8</td><td style=\"text-align:left\" title=\"6\">6</td></tr><tr><td style=\"text-align:left\" title=\"7.6\">7.6</td><td style=\"text-align:left\" title=\"0.14\">0.14</td><td style=\"text-align:left\" title=\"0.74\">0.74</td><td style=\"text-align:left\" title=\"1.6\">1.6</td><td style=\"text-align:left\" title=\"0.04\">0.04</td><td style=\"text-align:left\" title=\"27.0\">27.0</td><td style=\"text-align:left\" title=\"103.0\">103.0</td><td style=\"text-align:left\" title=\"0.9916\">0.9916</td><td style=\"text-align:left\" title=\"3.07\">3.07</td><td style=\"text-align:left\" title=\"0.4\">0.4</td><td style=\"text-align:left\" title=\"10.8\">10.8</td><td style=\"text-align:left\" title=\"7\">7</td></tr><tr><td style=\"text-align:left\" title=\"5.0\">5.0</td><td style=\"text-align:left\" title=\"0.29\">0.29</td><td style=\"text-align:left\" title=\"0.54\">0.54</td><td style=\"text-align:left\" title=\"5.7\">5.7</td><td style=\"text-align:left\" title=\"0.035\">0.035</td><td style=\"text-align:left\" title=\"54.0\">54.0</td><td style=\"text-align:left\" title=\"155.0\">155.0</td><td style=\"text-align:left\" title=\"0.98976\">0.98976</td><td style=\"text-align:left\" title=\"3.27\">3.27</td><td style=\"text-align:left\" title=\"0.34\">0.34</td><td style=\"text-align:left\" title=\"12.9\">12.9</td><td style=\"text-align:left\" title=\"8\">8</td></tr><tr><td style=\"text-align:left\" title=\"6.0\">6.0</td><td style=\"text-align:left\" title=\"0.28\">0.28</td><td style=\"text-align:left\" title=\"0.22\">0.22</td><td style=\"text-align:left\" title=\"12.15\">12.15</td><td style=\"text-align:left\" title=\"0.048\">0.048</td><td style=\"text-align:left\" title=\"42.0\">42.0</td><td style=\"text-align:left\" title=\"163.0\">163.0</td><td style=\"text-align:left\" title=\"0.9957\">0.9957</td><td style=\"text-align:left\" title=\"3.2\">3.2</td><td style=\"text-align:left\" title=\"0.46\">0.46</td><td style=\"text-align:left\" title=\"10.1\">10.1</td><td style=\"text-align:left\" title=\"5\">5</td></tr><tr><td style=\"text-align:left\" title=\"9.8\">9.8</td><td style=\"text-align:left\" title=\"0.93\">0.93</td><td style=\"text-align:left\" title=\"0.45\">0.45</td><td style=\"text-align:left\" title=\"8.6\">8.6</td><td style=\"text-align:left\" title=\"0.052\">0.052</td><td style=\"text-align:left\" title=\"34.0\">34.0</td><td style=\"text-align:left\" title=\"187.0\">187.0</td><td style=\"text-align:left\" title=\"0.9994\">0.9994</td><td style=\"text-align:left\" title=\"3.12\">3.12</td><td style=\"text-align:left\" title=\"0.59\">0.59</td><td style=\"text-align:left\" title=\"10.2\">10.2</td><td style=\"text-align:left\" title=\"4\">4</td></tr></table><p>... with 4402 more rows. Shape: 4408 x 12. \n",
       "</p></body></html>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = DataFrame.readCSV(\"data/winequality-white-train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "482f25c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val (X, y) = getXy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eeaec5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31 0.23529412 0.21084337 0.012269938 0.12166172 0.020905923 0.3573086 0.102756895 0.47272727 0.23255815 0.45 5.0"
     ]
    }
   ],
   "source": [
    "X[0].forEach { print(\"$it \") }\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97d722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val dataset = OnHeapDataset.create(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf91cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintingCallback : Callback() {\n",
    "    override fun onEpochEnd(epoch: Int, event: EpochTrainingEvent, logs: TrainingHistory) {\n",
    "        println(\"Epoch: $epoch - loss: ${event.lossValue} - val loss: ${event.valLossValue}\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcd686d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val model = Sequential.of(\n",
    "    Input(11),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(32),\n",
    "    Dense(1, activation = Activations.Linear)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b8ff734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - loss: 1.2947943210601807 - val loss: 0.773218035697937\n",
      "Epoch: 2 - loss: 0.6644443869590759 - val loss: 0.7584826946258545\n",
      "Epoch: 3 - loss: 0.6489058136940002 - val loss: 0.7261059880256653\n",
      "Epoch: 4 - loss: 0.6372713446617126 - val loss: 0.717948317527771\n",
      "Epoch: 5 - loss: 0.6304600238800049 - val loss: 0.7115525603294373\n",
      "Epoch: 6 - loss: 0.6276894211769104 - val loss: 0.7113010883331299\n",
      "Epoch: 7 - loss: 0.6252312064170837 - val loss: 0.7048158049583435\n",
      "Epoch: 8 - loss: 0.6236007809638977 - val loss: 0.705267071723938\n",
      "Epoch: 9 - loss: 0.6222526431083679 - val loss: 0.7029525637626648\n",
      "Epoch: 10 - loss: 0.621122419834137 - val loss: 0.7012268304824829\n",
      "Epoch: 11 - loss: 0.6191408038139343 - val loss: 0.7001461386680603\n",
      "Epoch: 12 - loss: 0.6182299256324768 - val loss: 0.6984177827835083\n",
      "Epoch: 13 - loss: 0.617371678352356 - val loss: 0.6960034966468811\n",
      "Epoch: 14 - loss: 0.6160566806793213 - val loss: 0.6974270939826965\n",
      "Epoch: 15 - loss: 0.615060567855835 - val loss: 0.6967469453811646\n",
      "Epoch: 16 - loss: 0.6144898533821106 - val loss: 0.6941633224487305\n",
      "Epoch: 17 - loss: 0.6135936975479126 - val loss: 0.6936944723129272\n",
      "Epoch: 18 - loss: 0.6126524806022644 - val loss: 0.6918780207633972\n",
      "Epoch: 19 - loss: 0.6120546460151672 - val loss: 0.6908629536628723\n",
      "Epoch: 20 - loss: 0.6113142371177673 - val loss: 0.6892496943473816\n",
      "Epoch: 21 - loss: 0.6106539964675903 - val loss: 0.689306378364563\n",
      "Epoch: 22 - loss: 0.6102376580238342 - val loss: 0.6860830783843994\n",
      "Epoch: 23 - loss: 0.608939528465271 - val loss: 0.68670254945755\n",
      "Epoch: 24 - loss: 0.6084297299385071 - val loss: 0.6866790056228638\n",
      "Epoch: 25 - loss: 0.6071731448173523 - val loss: 0.684292197227478\n",
      "Epoch: 26 - loss: 0.6066423654556274 - val loss: 0.6824212074279785\n",
      "Epoch: 27 - loss: 0.6066845059394836 - val loss: 0.681155264377594\n",
      "Epoch: 28 - loss: 0.6059937477111816 - val loss: 0.6792955994606018\n",
      "Epoch: 29 - loss: 0.6040715575218201 - val loss: 0.6774581074714661\n",
      "Epoch: 30 - loss: 0.6023414731025696 - val loss: 0.6744691133499146\n",
      "Epoch: 31 - loss: 0.6000173091888428 - val loss: 0.6701927185058594\n",
      "Epoch: 32 - loss: 0.5976123213768005 - val loss: 0.6666970252990723\n",
      "Epoch: 33 - loss: 0.595059871673584 - val loss: 0.6642181873321533\n",
      "Epoch: 34 - loss: 0.5928362011909485 - val loss: 0.6619483232498169\n",
      "Epoch: 35 - loss: 0.5905972123146057 - val loss: 0.659834623336792\n",
      "Epoch: 36 - loss: 0.5881291627883911 - val loss: 0.6572461128234863\n",
      "Epoch: 37 - loss: 0.5862794518470764 - val loss: 0.6548223495483398\n",
      "Epoch: 38 - loss: 0.5848523378372192 - val loss: 0.6525136828422546\n",
      "Epoch: 39 - loss: 0.583309531211853 - val loss: 0.6506174206733704\n",
      "Epoch: 40 - loss: 0.5820298790931702 - val loss: 0.6489490270614624\n",
      "Epoch: 41 - loss: 0.5808958411216736 - val loss: 0.6469607949256897\n",
      "Epoch: 42 - loss: 0.5804282426834106 - val loss: 0.6449113488197327\n",
      "Epoch: 43 - loss: 0.5782015323638916 - val loss: 0.6437588334083557\n",
      "Epoch: 44 - loss: 0.5782069563865662 - val loss: 0.642185389995575\n",
      "Epoch: 45 - loss: 0.5765901207923889 - val loss: 0.6411561369895935\n",
      "Epoch: 46 - loss: 0.5753071904182434 - val loss: 0.640055775642395\n",
      "Epoch: 47 - loss: 0.574275553226471 - val loss: 0.6390700340270996\n",
      "Epoch: 48 - loss: 0.5734093189239502 - val loss: 0.6378882527351379\n",
      "Epoch: 49 - loss: 0.5727986693382263 - val loss: 0.6368252635002136\n",
      "Epoch: 50 - loss: 0.5716883540153503 - val loss: 0.6361750960350037\n",
      "Epoch: 51 - loss: 0.5712254047393799 - val loss: 0.6353126764297485\n",
      "Epoch: 52 - loss: 0.5707988739013672 - val loss: 0.6348450183868408\n",
      "Epoch: 53 - loss: 0.5702178478240967 - val loss: 0.6345393061637878\n",
      "Epoch: 54 - loss: 0.5695651769638062 - val loss: 0.6338974237442017\n",
      "Epoch: 55 - loss: 0.5689529180526733 - val loss: 0.6333817839622498\n",
      "Epoch: 56 - loss: 0.5681563019752502 - val loss: 0.6331701278686523\n",
      "Epoch: 57 - loss: 0.5675403475761414 - val loss: 0.6323970556259155\n",
      "Epoch: 58 - loss: 0.5664854645729065 - val loss: 0.632113516330719\n",
      "Epoch: 59 - loss: 0.5658783316612244 - val loss: 0.6316038370132446\n",
      "Epoch: 60 - loss: 0.5653669834136963 - val loss: 0.6307439804077148\n",
      "Epoch: 61 - loss: 0.5644136071205139 - val loss: 0.6301499605178833\n",
      "Epoch: 62 - loss: 0.5635761618614197 - val loss: 0.6289557218551636\n",
      "Epoch: 63 - loss: 0.5634961724281311 - val loss: 0.6281747817993164\n",
      "Epoch: 64 - loss: 0.5631715655326843 - val loss: 0.6287388205528259\n",
      "Epoch: 65 - loss: 0.5621289610862732 - val loss: 0.6268985867500305\n",
      "Epoch: 66 - loss: 0.5613457560539246 - val loss: 0.6265138983726501\n",
      "Epoch: 67 - loss: 0.5608494281768799 - val loss: 0.6256933808326721\n",
      "Epoch: 68 - loss: 0.5600972175598145 - val loss: 0.6250013709068298\n",
      "Epoch: 69 - loss: 0.5600073337554932 - val loss: 0.6247110366821289\n",
      "Epoch: 70 - loss: 0.5588199496269226 - val loss: 0.6241521835327148\n",
      "Epoch: 71 - loss: 0.5585845708847046 - val loss: 0.6234790682792664\n",
      "Epoch: 72 - loss: 0.5584806203842163 - val loss: 0.622797966003418\n",
      "Epoch: 73 - loss: 0.5576328635215759 - val loss: 0.6235579252243042\n",
      "Epoch: 74 - loss: 0.5569495558738708 - val loss: 0.6231493949890137\n",
      "Epoch: 75 - loss: 0.5567168593406677 - val loss: 0.6216210722923279\n",
      "Epoch: 76 - loss: 0.5563169717788696 - val loss: 0.6212896108627319\n",
      "Epoch: 77 - loss: 0.5558553338050842 - val loss: 0.6207512617111206\n",
      "Epoch: 78 - loss: 0.555544912815094 - val loss: 0.6208788156509399\n",
      "Epoch: 79 - loss: 0.5549701452255249 - val loss: 0.6197407245635986\n",
      "Epoch: 80 - loss: 0.5544376969337463 - val loss: 0.618880033493042\n",
      "Epoch: 81 - loss: 0.5541403889656067 - val loss: 0.6193864345550537\n",
      "Epoch: 82 - loss: 0.5534945130348206 - val loss: 0.618374764919281\n",
      "Epoch: 83 - loss: 0.5532500147819519 - val loss: 0.6179329752922058\n",
      "Epoch: 84 - loss: 0.5524238348007202 - val loss: 0.6171266436576843\n",
      "Epoch: 85 - loss: 0.5525665283203125 - val loss: 0.6167244911193848\n",
      "Epoch: 86 - loss: 0.552069365978241 - val loss: 0.6164655089378357\n",
      "Epoch: 87 - loss: 0.5516485571861267 - val loss: 0.6155699491500854\n",
      "Epoch: 88 - loss: 0.5511468648910522 - val loss: 0.6141382455825806\n",
      "Epoch: 89 - loss: 0.5501830577850342 - val loss: 0.6128064393997192\n",
      "Epoch: 90 - loss: 0.5504518747329712 - val loss: 0.6138814091682434\n",
      "Epoch: 91 - loss: 0.5498234629631042 - val loss: 0.6132930517196655\n",
      "Epoch: 92 - loss: 0.5500544309616089 - val loss: 0.6120027899742126\n",
      "Epoch: 93 - loss: 0.5493417382240295 - val loss: 0.6116766929626465\n",
      "Epoch: 94 - loss: 0.5486004948616028 - val loss: 0.611071765422821\n",
      "Epoch: 95 - loss: 0.5483137965202332 - val loss: 0.6096612811088562\n",
      "Epoch: 96 - loss: 0.5478420257568359 - val loss: 0.6087983846664429\n",
      "Epoch: 97 - loss: 0.5477503538131714 - val loss: 0.6078725457191467\n",
      "Epoch: 98 - loss: 0.547210156917572 - val loss: 0.6067362427711487\n",
      "Epoch: 99 - loss: 0.5471242666244507 - val loss: 0.607947826385498\n",
      "Epoch: 100 - loss: 0.545973539352417 - val loss: 0.606651246547699\n",
      "Epoch: 101 - loss: 0.546795129776001 - val loss: 0.609753429889679\n",
      "Epoch: 102 - loss: 0.5463944673538208 - val loss: 0.6066460609436035\n",
      "Epoch: 103 - loss: 0.5458043217658997 - val loss: 0.6060531735420227\n",
      "Epoch: 104 - loss: 0.5449532270431519 - val loss: 0.6050703525543213\n",
      "Epoch: 105 - loss: 0.5437966585159302 - val loss: 0.6035512685775757\n",
      "Epoch: 106 - loss: 0.5441169142723083 - val loss: 0.6047176122665405\n",
      "Epoch: 107 - loss: 0.5439429879188538 - val loss: 0.6047281622886658\n",
      "Epoch: 108 - loss: 0.543525755405426 - val loss: 0.6057966947555542\n",
      "Epoch: 109 - loss: 0.5428943037986755 - val loss: 0.6039016842842102\n",
      "Epoch: 110 - loss: 0.5426264405250549 - val loss: 0.6038918495178223\n",
      "Epoch: 111 - loss: 0.5424317717552185 - val loss: 0.6034985184669495\n",
      "Epoch: 112 - loss: 0.5416520833969116 - val loss: 0.6033264398574829\n",
      "Epoch: 113 - loss: 0.5409572124481201 - val loss: 0.6010852456092834\n",
      "Epoch: 114 - loss: 0.5409461259841919 - val loss: 0.6022508144378662\n",
      "Epoch: 115 - loss: 0.5410051941871643 - val loss: 0.602388322353363\n",
      "Epoch: 116 - loss: 0.5411412119865417 - val loss: 0.6024137735366821\n",
      "Epoch: 117 - loss: 0.5398611426353455 - val loss: 0.6008501052856445\n",
      "Epoch: 118 - loss: 0.5416886806488037 - val loss: 0.6035059690475464\n",
      "Epoch: 119 - loss: 0.5395566821098328 - val loss: 0.6009377837181091\n",
      "Epoch: 120 - loss: 0.5400550365447998 - val loss: 0.6016514301300049\n",
      "Epoch: 121 - loss: 0.5394683480262756 - val loss: 0.6011817455291748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 122 - loss: 0.5390428900718689 - val loss: 0.6014110445976257\n",
      "Epoch: 123 - loss: 0.5392025709152222 - val loss: 0.6021389961242676\n",
      "Epoch: 124 - loss: 0.5386915802955627 - val loss: 0.6010087728500366\n",
      "Epoch: 125 - loss: 0.5390177965164185 - val loss: 0.6011297106742859\n",
      "Epoch: 126 - loss: 0.5386765003204346 - val loss: 0.6003568768501282\n",
      "Epoch: 127 - loss: 0.538011372089386 - val loss: 0.5997979044914246\n",
      "Epoch: 128 - loss: 0.537674069404602 - val loss: 0.5995385050773621\n",
      "Epoch: 129 - loss: 0.5379180908203125 - val loss: 0.5995094776153564\n",
      "Epoch: 130 - loss: 0.5395511984825134 - val loss: 0.6000112295150757\n",
      "Epoch: 131 - loss: 0.5371657609939575 - val loss: 0.5984452962875366\n",
      "Epoch: 132 - loss: 0.5362866520881653 - val loss: 0.5986142158508301\n",
      "Epoch: 133 - loss: 0.5356083512306213 - val loss: 0.5977197885513306\n",
      "Epoch: 134 - loss: 0.5383086800575256 - val loss: 0.5991058945655823\n",
      "Epoch: 135 - loss: 0.5357279181480408 - val loss: 0.5983167886734009\n",
      "Epoch: 136 - loss: 0.5377992391586304 - val loss: 0.5998851656913757\n",
      "Epoch: 137 - loss: 0.5360485315322876 - val loss: 0.5985831618309021\n",
      "Epoch: 138 - loss: 0.5351318120956421 - val loss: 0.5976906418800354\n",
      "Epoch: 139 - loss: 0.5355489253997803 - val loss: 0.5980619788169861\n",
      "Epoch: 140 - loss: 0.5348723530769348 - val loss: 0.5979145169258118\n",
      "Epoch: 141 - loss: 0.535653293132782 - val loss: 0.5982996821403503\n",
      "Epoch: 142 - loss: 0.5356855988502502 - val loss: 0.597577691078186\n",
      "Epoch: 143 - loss: 0.5345832705497742 - val loss: 0.5971876382827759\n",
      "Epoch: 144 - loss: 0.5340266823768616 - val loss: 0.5975142121315002\n",
      "Epoch: 145 - loss: 0.5334884524345398 - val loss: 0.5961695313453674\n",
      "Epoch: 146 - loss: 0.5337082743644714 - val loss: 0.5952321887016296\n",
      "Epoch: 147 - loss: 0.5333974361419678 - val loss: 0.5952291488647461\n",
      "Epoch: 148 - loss: 0.5335789322853088 - val loss: 0.5956807136535645\n",
      "Epoch: 149 - loss: 0.5344339609146118 - val loss: 0.5967084169387817\n",
      "Epoch: 150 - loss: 0.5347442030906677 - val loss: 0.598020076751709\n",
      "Epoch: 151 - loss: 0.533543050289154 - val loss: 0.5965386033058167\n",
      "Epoch: 152 - loss: 0.532397985458374 - val loss: 0.5966688394546509\n",
      "Epoch: 153 - loss: 0.5328192710876465 - val loss: 0.5963754653930664\n",
      "Epoch: 154 - loss: 0.5314762592315674 - val loss: 0.5944836139678955\n",
      "Epoch: 155 - loss: 0.5314157009124756 - val loss: 0.5939715504646301\n",
      "Epoch: 156 - loss: 0.5313237905502319 - val loss: 0.594139039516449\n",
      "Epoch: 157 - loss: 0.5314120650291443 - val loss: 0.5943788886070251\n",
      "Epoch: 158 - loss: 0.5333517789840698 - val loss: 0.5975381135940552\n",
      "Epoch: 159 - loss: 0.5309950709342957 - val loss: 0.5939901471138\n",
      "Epoch: 160 - loss: 0.532118558883667 - val loss: 0.5964791178703308\n",
      "Epoch: 161 - loss: 0.5323342084884644 - val loss: 0.5953980088233948\n",
      "Epoch: 162 - loss: 0.5337243676185608 - val loss: 0.5972414612770081\n",
      "Epoch: 163 - loss: 0.5303176641464233 - val loss: 0.5934595465660095\n",
      "Epoch: 164 - loss: 0.5326074957847595 - val loss: 0.5978342294692993\n",
      "Epoch: 165 - loss: 0.5314176678657532 - val loss: 0.5958548784255981\n",
      "Epoch: 166 - loss: 0.528753399848938 - val loss: 0.5926151871681213\n",
      "Epoch: 167 - loss: 0.5287882685661316 - val loss: 0.5924819111824036\n",
      "Epoch: 168 - loss: 0.5280882716178894 - val loss: 0.5926421284675598\n",
      "Epoch: 169 - loss: 0.5280941724777222 - val loss: 0.5934523344039917\n",
      "Epoch: 170 - loss: 0.527258574962616 - val loss: 0.5928407907485962\n",
      "Epoch: 171 - loss: 0.5278799533843994 - val loss: 0.592826783657074\n",
      "Epoch: 172 - loss: 0.527043879032135 - val loss: 0.5917986035346985\n",
      "Epoch: 173 - loss: 0.5278352499008179 - val loss: 0.5927034020423889\n",
      "Epoch: 174 - loss: 0.5272346138954163 - val loss: 0.5927734375\n",
      "Epoch: 175 - loss: 0.526835024356842 - val loss: 0.5925408005714417\n",
      "Epoch: 176 - loss: 0.5267457365989685 - val loss: 0.5923578143119812\n",
      "Epoch: 177 - loss: 0.5268738269805908 - val loss: 0.5923233032226562\n",
      "Epoch: 178 - loss: 0.5268101096153259 - val loss: 0.5928115248680115\n",
      "Epoch: 179 - loss: 0.5262886881828308 - val loss: 0.5924577116966248\n",
      "Epoch: 180 - loss: 0.5262243151664734 - val loss: 0.5917490124702454\n",
      "Epoch: 181 - loss: 0.5263170599937439 - val loss: 0.5927869081497192\n",
      "Epoch: 182 - loss: 0.5257058143615723 - val loss: 0.592492938041687\n",
      "Epoch: 183 - loss: 0.5256645083427429 - val loss: 0.592812716960907\n",
      "Epoch: 184 - loss: 0.5253063440322876 - val loss: 0.5924694538116455\n",
      "Epoch: 185 - loss: 0.5255783200263977 - val loss: 0.5925894975662231\n",
      "Epoch: 186 - loss: 0.5249184966087341 - val loss: 0.5907239317893982\n",
      "Epoch: 187 - loss: 0.5250077843666077 - val loss: 0.5927110910415649\n",
      "Epoch: 188 - loss: 0.5243757367134094 - val loss: 0.5915617942810059\n",
      "Epoch: 189 - loss: 0.5248624682426453 - val loss: 0.5925314426422119\n",
      "Epoch: 190 - loss: 0.5241950154304504 - val loss: 0.592331051826477\n",
      "Epoch: 191 - loss: 0.5245729088783264 - val loss: 0.5926598906517029\n",
      "Epoch: 192 - loss: 0.5247601866722107 - val loss: 0.5916715860366821\n",
      "Epoch: 193 - loss: 0.523842453956604 - val loss: 0.5911496877670288\n",
      "Epoch: 194 - loss: 0.5236918926239014 - val loss: 0.591711699962616\n",
      "Epoch: 195 - loss: 0.5239565968513489 - val loss: 0.5920602679252625\n",
      "Epoch: 196 - loss: 0.5237402319908142 - val loss: 0.5921998023986816\n",
      "Epoch: 197 - loss: 0.5238263607025146 - val loss: 0.5918193459510803\n",
      "Epoch: 198 - loss: 0.5233277082443237 - val loss: 0.5903942584991455\n",
      "Epoch: 199 - loss: 0.5228392481803894 - val loss: 0.5907193422317505\n",
      "Epoch: 200 - loss: 0.5231122374534607 - val loss: 0.5909183621406555\n",
      "Epoch: 201 - loss: 0.5228240489959717 - val loss: 0.5911338925361633\n",
      "Epoch: 202 - loss: 0.5230724215507507 - val loss: 0.5915420055389404\n",
      "Epoch: 203 - loss: 0.5225176811218262 - val loss: 0.5904102921485901\n",
      "Epoch: 204 - loss: 0.5228397846221924 - val loss: 0.5906821489334106\n",
      "Epoch: 205 - loss: 0.5222988128662109 - val loss: 0.5902288556098938\n",
      "Epoch: 206 - loss: 0.5219056010246277 - val loss: 0.5911173224449158\n",
      "Epoch: 207 - loss: 0.5221650004386902 - val loss: 0.5905075073242188\n",
      "Epoch: 208 - loss: 0.5225757956504822 - val loss: 0.5897770524024963\n",
      "Epoch: 209 - loss: 0.5221914649009705 - val loss: 0.5905376076698303\n",
      "Epoch: 210 - loss: 0.5245802998542786 - val loss: 0.589370846748352\n",
      "Epoch: 211 - loss: 0.5218828916549683 - val loss: 0.5894432663917542\n",
      "Epoch: 212 - loss: 0.5220322608947754 - val loss: 0.5899778604507446\n",
      "Epoch: 213 - loss: 0.5209468007087708 - val loss: 0.5897921919822693\n",
      "Epoch: 214 - loss: 0.5212887525558472 - val loss: 0.588622510433197\n",
      "Epoch: 215 - loss: 0.5209963321685791 - val loss: 0.589738130569458\n",
      "Epoch: 216 - loss: 0.5211373567581177 - val loss: 0.5888018608093262\n",
      "Epoch: 217 - loss: 0.5207722783088684 - val loss: 0.5902963280677795\n",
      "Epoch: 218 - loss: 0.5210641622543335 - val loss: 0.5889756083488464\n",
      "Epoch: 219 - loss: 0.5211129784584045 - val loss: 0.5897363424301147\n",
      "Epoch: 220 - loss: 0.5205517411231995 - val loss: 0.5888906717300415\n",
      "Epoch: 221 - loss: 0.5199020504951477 - val loss: 0.5886083841323853\n",
      "Epoch: 222 - loss: 0.5200751423835754 - val loss: 0.5893617272377014\n",
      "Epoch: 223 - loss: 0.5197946429252625 - val loss: 0.5879819989204407\n",
      "Epoch: 224 - loss: 0.519335150718689 - val loss: 0.5886024236679077\n",
      "Epoch: 225 - loss: 0.5195671916007996 - val loss: 0.5896403789520264\n",
      "Epoch: 226 - loss: 0.5199657082557678 - val loss: 0.5886356234550476\n",
      "Epoch: 227 - loss: 0.5195412635803223 - val loss: 0.5887736082077026\n",
      "Epoch: 228 - loss: 0.5189123749732971 - val loss: 0.5887184739112854\n",
      "Epoch: 229 - loss: 0.5187664031982422 - val loss: 0.5878834128379822\n",
      "Epoch: 230 - loss: 0.5192034244537354 - val loss: 0.5876355767250061\n",
      "Epoch: 231 - loss: 0.518933892250061 - val loss: 0.5880747437477112\n",
      "Epoch: 232 - loss: 0.5189350843429565 - val loss: 0.5897107124328613\n",
      "Epoch: 233 - loss: 0.5188115835189819 - val loss: 0.5894876718521118\n",
      "Epoch: 234 - loss: 0.519096314907074 - val loss: 0.5881627202033997\n",
      "Epoch: 235 - loss: 0.5181830525398254 - val loss: 0.5885772705078125\n",
      "Epoch: 236 - loss: 0.5186852812767029 - val loss: 0.5884591937065125\n",
      "Epoch: 237 - loss: 0.5183778405189514 - val loss: 0.5875721573829651\n",
      "Epoch: 238 - loss: 0.5188645720481873 - val loss: 0.5875855684280396\n",
      "Epoch: 239 - loss: 0.5179558396339417 - val loss: 0.5876176953315735\n",
      "Epoch: 240 - loss: 0.5184983015060425 - val loss: 0.5881977677345276\n",
      "Epoch: 241 - loss: 0.5178087949752808 - val loss: 0.588784396648407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 242 - loss: 0.5180151462554932 - val loss: 0.587979793548584\n",
      "Epoch: 243 - loss: 0.5173366069793701 - val loss: 0.5886611938476562\n",
      "Epoch: 244 - loss: 0.5182648301124573 - val loss: 0.5865639448165894\n",
      "Epoch: 245 - loss: 0.5171990990638733 - val loss: 0.5878034830093384\n",
      "Epoch: 246 - loss: 0.5180361866950989 - val loss: 0.58805251121521\n",
      "Epoch: 247 - loss: 0.5173376202583313 - val loss: 0.5878274440765381\n",
      "Epoch: 248 - loss: 0.5172377228736877 - val loss: 0.5888938307762146\n",
      "Epoch: 249 - loss: 0.5169693231582642 - val loss: 0.5876220464706421\n",
      "Epoch: 250 - loss: 0.5165412425994873 - val loss: 0.5880385041236877\n",
      "Epoch: 251 - loss: 0.5161919593811035 - val loss: 0.5876519680023193\n",
      "Epoch: 252 - loss: 0.5161256790161133 - val loss: 0.5877645611763\n",
      "Epoch: 253 - loss: 0.5159105658531189 - val loss: 0.5869523286819458\n",
      "Epoch: 254 - loss: 0.51690274477005 - val loss: 0.5875149965286255\n",
      "Epoch: 255 - loss: 0.5194682478904724 - val loss: 0.587762713432312\n",
      "Epoch: 256 - loss: 0.5195923447608948 - val loss: 0.5865758657455444\n",
      "Epoch: 257 - loss: 0.5156036615371704 - val loss: 0.5847808718681335\n",
      "Epoch: 258 - loss: 0.5163691639900208 - val loss: 0.58720862865448\n",
      "Epoch: 259 - loss: 0.5158419609069824 - val loss: 0.5862189531326294\n",
      "Epoch: 260 - loss: 0.5158176422119141 - val loss: 0.588473916053772\n",
      "Epoch: 261 - loss: 0.5154008269309998 - val loss: 0.584782063961029\n",
      "Epoch: 262 - loss: 0.5157237648963928 - val loss: 0.5862393975257874\n",
      "Epoch: 263 - loss: 0.516133189201355 - val loss: 0.5860275030136108\n",
      "Epoch: 264 - loss: 0.5166751742362976 - val loss: 0.5860868096351624\n",
      "Epoch: 265 - loss: 0.514745831489563 - val loss: 0.5846797823905945\n",
      "Epoch: 266 - loss: 0.5153543949127197 - val loss: 0.5863679647445679\n",
      "Epoch: 267 - loss: 0.5145882964134216 - val loss: 0.5851958990097046\n",
      "Epoch: 268 - loss: 0.514875054359436 - val loss: 0.5867037773132324\n",
      "Epoch: 269 - loss: 0.5159654021263123 - val loss: 0.5838598608970642\n",
      "Epoch: 270 - loss: 0.5151359438896179 - val loss: 0.5861931443214417\n",
      "Epoch: 271 - loss: 0.5154504179954529 - val loss: 0.5841222405433655\n",
      "Epoch: 272 - loss: 0.5144671201705933 - val loss: 0.5862873196601868\n",
      "Epoch: 273 - loss: 0.5142905116081238 - val loss: 0.5858302712440491\n",
      "Epoch: 274 - loss: 0.5141481757164001 - val loss: 0.5824897289276123\n",
      "Epoch: 275 - loss: 0.5144190788269043 - val loss: 0.5858544707298279\n",
      "Epoch: 276 - loss: 0.5136628746986389 - val loss: 0.5828672647476196\n",
      "Epoch: 277 - loss: 0.5136253833770752 - val loss: 0.5832864046096802\n",
      "Epoch: 278 - loss: 0.5151727199554443 - val loss: 0.5841218829154968\n",
      "Epoch: 279 - loss: 0.514825701713562 - val loss: 0.5833052396774292\n",
      "Epoch: 280 - loss: 0.5144115686416626 - val loss: 0.5846084356307983\n",
      "Epoch: 281 - loss: 0.5136944651603699 - val loss: 0.5826853513717651\n",
      "Epoch: 282 - loss: 0.5136850476264954 - val loss: 0.5844117403030396\n",
      "Epoch: 283 - loss: 0.5133164525032043 - val loss: 0.5828284621238708\n",
      "Epoch: 284 - loss: 0.5143771171569824 - val loss: 0.5843652486801147\n",
      "Epoch: 285 - loss: 0.5130131244659424 - val loss: 0.5816795229911804\n",
      "Epoch: 286 - loss: 0.5125619769096375 - val loss: 0.5825954079627991\n",
      "Epoch: 287 - loss: 0.5131627321243286 - val loss: 0.5835439562797546\n",
      "Epoch: 288 - loss: 0.5130552053451538 - val loss: 0.5848982334136963\n",
      "Epoch: 289 - loss: 0.5122542977333069 - val loss: 0.5827550292015076\n",
      "Epoch: 290 - loss: 0.5122487545013428 - val loss: 0.581561267375946\n",
      "Epoch: 291 - loss: 0.512497067451477 - val loss: 0.5823630094528198\n",
      "Epoch: 292 - loss: 0.5127956867218018 - val loss: 0.5840397477149963\n",
      "Epoch: 293 - loss: 0.5122458934783936 - val loss: 0.5820136070251465\n",
      "Epoch: 294 - loss: 0.5111680626869202 - val loss: 0.5814629197120667\n",
      "Epoch: 295 - loss: 0.5123592019081116 - val loss: 0.5831127762794495\n",
      "Epoch: 296 - loss: 0.5128208994865417 - val loss: 0.5847101807594299\n",
      "Epoch: 297 - loss: 0.5116515755653381 - val loss: 0.5830488801002502\n",
      "Epoch: 298 - loss: 0.5118961930274963 - val loss: 0.5809539556503296\n",
      "Epoch: 299 - loss: 0.5111793875694275 - val loss: 0.5813851356506348\n",
      "Epoch: 300 - loss: 0.513098955154419 - val loss: 0.5845384001731873\n",
      "Epoch: 301 - loss: 0.5116022229194641 - val loss: 0.5837931036949158\n",
      "Epoch: 302 - loss: 0.5110522508621216 - val loss: 0.5806731581687927\n",
      "Epoch: 303 - loss: 0.5114939212799072 - val loss: 0.5812363028526306\n",
      "Epoch: 304 - loss: 0.510712206363678 - val loss: 0.5807604193687439\n",
      "Epoch: 305 - loss: 0.5101481676101685 - val loss: 0.5804991722106934\n",
      "Epoch: 306 - loss: 0.5118727684020996 - val loss: 0.582303524017334\n",
      "Epoch: 307 - loss: 0.5129472613334656 - val loss: 0.5834322571754456\n",
      "Epoch: 308 - loss: 0.5110223889350891 - val loss: 0.5812546014785767\n",
      "Epoch: 309 - loss: 0.5100491046905518 - val loss: 0.5814388394355774\n",
      "Epoch: 310 - loss: 0.511553943157196 - val loss: 0.5821280479431152\n",
      "Epoch: 311 - loss: 0.5101528167724609 - val loss: 0.5809337496757507\n",
      "Epoch: 312 - loss: 0.5101870894432068 - val loss: 0.5797618627548218\n",
      "Epoch: 313 - loss: 0.5107843279838562 - val loss: 0.581024706363678\n",
      "Epoch: 314 - loss: 0.5100755095481873 - val loss: 0.5794329047203064\n",
      "Epoch: 315 - loss: 0.509770929813385 - val loss: 0.580110490322113\n",
      "Epoch: 316 - loss: 0.5093616843223572 - val loss: 0.5802692174911499\n",
      "Epoch: 317 - loss: 0.5094377994537354 - val loss: 0.5813655257225037\n",
      "Epoch: 318 - loss: 0.5107312202453613 - val loss: 0.5803130269050598\n",
      "Epoch: 319 - loss: 0.5099380612373352 - val loss: 0.5792837738990784\n",
      "Epoch: 320 - loss: 0.5101928114891052 - val loss: 0.5794463157653809\n",
      "Epoch: 321 - loss: 0.5096905827522278 - val loss: 0.5791714787483215\n",
      "Epoch: 322 - loss: 0.5088919401168823 - val loss: 0.5798670053482056\n",
      "Epoch: 323 - loss: 0.5092959403991699 - val loss: 0.5804356932640076\n",
      "Epoch: 324 - loss: 0.5096562504768372 - val loss: 0.5794690847396851\n",
      "Epoch: 325 - loss: 0.5089282393455505 - val loss: 0.5791677236557007\n",
      "Epoch: 326 - loss: 0.5085587501525879 - val loss: 0.5804129242897034\n",
      "Epoch: 327 - loss: 0.5087933540344238 - val loss: 0.5797703266143799\n",
      "Epoch: 328 - loss: 0.5090608596801758 - val loss: 0.5798851847648621\n",
      "Epoch: 329 - loss: 0.5110253691673279 - val loss: 0.5819107890129089\n",
      "Epoch: 330 - loss: 0.5089424252510071 - val loss: 0.5792422890663147\n",
      "Epoch: 331 - loss: 0.5102892518043518 - val loss: 0.5794349908828735\n",
      "Epoch: 332 - loss: 0.507892906665802 - val loss: 0.5791351199150085\n",
      "Epoch: 333 - loss: 0.5088969469070435 - val loss: 0.5793455839157104\n",
      "Epoch: 334 - loss: 0.5088226795196533 - val loss: 0.5781387090682983\n",
      "Epoch: 335 - loss: 0.5079491138458252 - val loss: 0.5800977945327759\n",
      "Epoch: 336 - loss: 0.5085002183914185 - val loss: 0.5797683596611023\n",
      "Epoch: 337 - loss: 0.5083146691322327 - val loss: 0.5794863104820251\n",
      "Epoch: 338 - loss: 0.508922278881073 - val loss: 0.5794400572776794\n",
      "Epoch: 339 - loss: 0.5085244178771973 - val loss: 0.5782982707023621\n",
      "Epoch: 340 - loss: 0.508138120174408 - val loss: 0.5778224468231201\n",
      "Epoch: 341 - loss: 0.5069635510444641 - val loss: 0.579086184501648\n",
      "Epoch: 342 - loss: 0.5076652765274048 - val loss: 0.5792060494422913\n",
      "Epoch: 343 - loss: 0.5092580914497375 - val loss: 0.5773554444313049\n",
      "Epoch: 344 - loss: 0.5071339011192322 - val loss: 0.5787389278411865\n",
      "Epoch: 345 - loss: 0.5075029730796814 - val loss: 0.5793614983558655\n",
      "Epoch: 346 - loss: 0.5080087184906006 - val loss: 0.5792458057403564\n",
      "Epoch: 347 - loss: 0.5082170963287354 - val loss: 0.5783005952835083\n",
      "Epoch: 348 - loss: 0.5077165961265564 - val loss: 0.5774024128913879\n",
      "Epoch: 349 - loss: 0.5069064497947693 - val loss: 0.5775864124298096\n",
      "Epoch: 350 - loss: 0.5073286294937134 - val loss: 0.5791513323783875\n",
      "Epoch: 351 - loss: 0.5077804923057556 - val loss: 0.5764499306678772\n",
      "Epoch: 352 - loss: 0.5070509910583496 - val loss: 0.5777022838592529\n",
      "Epoch: 353 - loss: 0.5069092512130737 - val loss: 0.5786593556404114\n",
      "Epoch: 354 - loss: 0.5082290172576904 - val loss: 0.5774690508842468\n",
      "Epoch: 355 - loss: 0.5074760913848877 - val loss: 0.577897310256958\n",
      "Epoch: 356 - loss: 0.5067612528800964 - val loss: 0.5770355463027954\n",
      "Epoch: 357 - loss: 0.507689893245697 - val loss: 0.5774782299995422\n",
      "Epoch: 358 - loss: 0.5070145130157471 - val loss: 0.5779051184654236\n",
      "Epoch: 359 - loss: 0.5075324773788452 - val loss: 0.5764762759208679\n",
      "Epoch: 360 - loss: 0.5068844556808472 - val loss: 0.5767841935157776\n",
      "Epoch: 361 - loss: 0.5064626336097717 - val loss: 0.5757839679718018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 362 - loss: 0.5060458779335022 - val loss: 0.577431321144104\n",
      "Epoch: 363 - loss: 0.5063998699188232 - val loss: 0.5771939158439636\n",
      "Epoch: 364 - loss: 0.5069701075553894 - val loss: 0.5774621963500977\n",
      "Epoch: 365 - loss: 0.5063921213150024 - val loss: 0.575785219669342\n",
      "Epoch: 366 - loss: 0.50632643699646 - val loss: 0.5772136449813843\n",
      "Epoch: 367 - loss: 0.5064504742622375 - val loss: 0.5773503184318542\n",
      "Epoch: 368 - loss: 0.5063719153404236 - val loss: 0.5768935084342957\n",
      "Epoch: 369 - loss: 0.5055451989173889 - val loss: 0.5765202045440674\n",
      "Epoch: 370 - loss: 0.5060255527496338 - val loss: 0.5768101215362549\n",
      "Epoch: 371 - loss: 0.5056856274604797 - val loss: 0.5769665241241455\n",
      "Epoch: 372 - loss: 0.5066598653793335 - val loss: 0.5757459998130798\n",
      "Epoch: 373 - loss: 0.5063762664794922 - val loss: 0.5755559802055359\n",
      "Epoch: 374 - loss: 0.5055550932884216 - val loss: 0.5753026008605957\n",
      "Epoch: 375 - loss: 0.5053505301475525 - val loss: 0.5764802694320679\n",
      "Epoch: 376 - loss: 0.5051464438438416 - val loss: 0.576012134552002\n",
      "Epoch: 377 - loss: 0.5048264861106873 - val loss: 0.5750480890274048\n",
      "Epoch: 378 - loss: 0.5045351386070251 - val loss: 0.5762585997581482\n",
      "Epoch: 379 - loss: 0.5052536129951477 - val loss: 0.5761452317237854\n",
      "Epoch: 380 - loss: 0.5051339864730835 - val loss: 0.5768073797225952\n",
      "Epoch: 381 - loss: 0.5050066709518433 - val loss: 0.5764265656471252\n",
      "Epoch: 382 - loss: 0.5054279565811157 - val loss: 0.5776458978652954\n",
      "Epoch: 383 - loss: 0.5059162974357605 - val loss: 0.575477123260498\n",
      "Epoch: 384 - loss: 0.5051556825637817 - val loss: 0.575754702091217\n",
      "Epoch: 385 - loss: 0.5059705376625061 - val loss: 0.5738747119903564\n",
      "Epoch: 386 - loss: 0.5049947500228882 - val loss: 0.5753471851348877\n",
      "Epoch: 387 - loss: 0.5045945644378662 - val loss: 0.5748518109321594\n",
      "Epoch: 388 - loss: 0.5040552020072937 - val loss: 0.5754691958427429\n",
      "Epoch: 389 - loss: 0.5047720074653625 - val loss: 0.5754915475845337\n",
      "Epoch: 390 - loss: 0.504806637763977 - val loss: 0.5757002234458923\n",
      "Epoch: 391 - loss: 0.5045701861381531 - val loss: 0.5752295851707458\n",
      "Epoch: 392 - loss: 0.5040403008460999 - val loss: 0.5748375058174133\n",
      "Epoch: 393 - loss: 0.5036799907684326 - val loss: 0.5759251117706299\n",
      "Epoch: 394 - loss: 0.5041622519493103 - val loss: 0.575628399848938\n",
      "Epoch: 395 - loss: 0.504168689250946 - val loss: 0.5754644274711609\n",
      "Epoch: 396 - loss: 0.5036203861236572 - val loss: 0.5749319791793823\n",
      "Epoch: 397 - loss: 0.5034534931182861 - val loss: 0.575332760810852\n",
      "Epoch: 398 - loss: 0.5039491057395935 - val loss: 0.5769236087799072\n",
      "Epoch: 399 - loss: 0.5044188499450684 - val loss: 0.5773075222969055\n",
      "Epoch: 400 - loss: 0.5041671395301819 - val loss: 0.5756460428237915\n",
      "Epoch: 401 - loss: 0.5044008493423462 - val loss: 0.5760730504989624\n",
      "Epoch: 402 - loss: 0.5045878291130066 - val loss: 0.5736199617385864\n",
      "Epoch: 403 - loss: 0.5037293434143066 - val loss: 0.573421061038971\n",
      "Epoch: 404 - loss: 0.5033460855484009 - val loss: 0.5751946568489075\n",
      "Epoch: 405 - loss: 0.5030930042266846 - val loss: 0.5759196877479553\n",
      "Epoch: 406 - loss: 0.5031676292419434 - val loss: 0.5745205283164978\n",
      "Epoch: 407 - loss: 0.5029199123382568 - val loss: 0.5752915740013123\n",
      "Epoch: 408 - loss: 0.5027393698692322 - val loss: 0.574438214302063\n",
      "Epoch: 409 - loss: 0.5021136999130249 - val loss: 0.5748785734176636\n",
      "Epoch: 410 - loss: 0.5025607943534851 - val loss: 0.5742577910423279\n",
      "Epoch: 411 - loss: 0.5030357837677002 - val loss: 0.5756941437721252\n",
      "Epoch: 412 - loss: 0.50325608253479 - val loss: 0.5761018991470337\n",
      "Epoch: 413 - loss: 0.5030901432037354 - val loss: 0.5761569738388062\n",
      "Epoch: 414 - loss: 0.5031387209892273 - val loss: 0.5765103101730347\n",
      "Epoch: 415 - loss: 0.5033413767814636 - val loss: 0.5744901299476624\n",
      "Epoch: 416 - loss: 0.5021668672561646 - val loss: 0.5741690993309021\n",
      "Epoch: 417 - loss: 0.5020599365234375 - val loss: 0.5743252635002136\n",
      "Epoch: 418 - loss: 0.5017032623291016 - val loss: 0.5742711424827576\n",
      "Epoch: 419 - loss: 0.5016236305236816 - val loss: 0.5734214186668396\n",
      "Epoch: 420 - loss: 0.501266598701477 - val loss: 0.5749809145927429\n",
      "Epoch: 421 - loss: 0.5020264387130737 - val loss: 0.5721459984779358\n",
      "Epoch: 422 - loss: 0.5015711784362793 - val loss: 0.5751880407333374\n",
      "Epoch: 423 - loss: 0.5020077228546143 - val loss: 0.5753372311592102\n",
      "Epoch: 424 - loss: 0.5018796920776367 - val loss: 0.5751181244850159\n",
      "Epoch: 425 - loss: 0.5015906691551208 - val loss: 0.5763669610023499\n",
      "Epoch: 426 - loss: 0.5020574331283569 - val loss: 0.5763356685638428\n",
      "Epoch: 427 - loss: 0.5026935935020447 - val loss: 0.5760377645492554\n",
      "Epoch: 428 - loss: 0.502335786819458 - val loss: 0.5764349102973938\n",
      "Epoch: 429 - loss: 0.5025367140769958 - val loss: 0.5752579569816589\n",
      "Epoch: 430 - loss: 0.5019238591194153 - val loss: 0.5740262269973755\n",
      "Epoch: 431 - loss: 0.5011932849884033 - val loss: 0.57332843542099\n",
      "Epoch: 432 - loss: 0.5008039474487305 - val loss: 0.5746405720710754\n",
      "Epoch: 433 - loss: 0.5012704133987427 - val loss: 0.5755833983421326\n",
      "Epoch: 434 - loss: 0.5018082857131958 - val loss: 0.5755130648612976\n",
      "Epoch: 435 - loss: 0.502016544342041 - val loss: 0.575427770614624\n",
      "Epoch: 436 - loss: 0.5020188689231873 - val loss: 0.5750991106033325\n",
      "Epoch: 437 - loss: 0.5013880133628845 - val loss: 0.5741617679595947\n",
      "Epoch: 438 - loss: 0.5011978149414062 - val loss: 0.5747159719467163\n",
      "Epoch: 439 - loss: 0.5009061098098755 - val loss: 0.5733847618103027\n",
      "Epoch: 440 - loss: 0.5013247132301331 - val loss: 0.5748094916343689\n",
      "Epoch: 441 - loss: 0.5008716583251953 - val loss: 0.5747128129005432\n",
      "Epoch: 442 - loss: 0.5013929009437561 - val loss: 0.5756784081459045\n",
      "Epoch: 443 - loss: 0.5011216402053833 - val loss: 0.5758488178253174\n",
      "Epoch: 444 - loss: 0.5009716153144836 - val loss: 0.5744510293006897\n",
      "Epoch: 445 - loss: 0.5014312267303467 - val loss: 0.5752640962600708\n",
      "Epoch: 446 - loss: 0.5010855793952942 - val loss: 0.5739407539367676\n",
      "Epoch: 447 - loss: 0.5002012252807617 - val loss: 0.574288010597229\n",
      "Epoch: 448 - loss: 0.5001670122146606 - val loss: 0.5745527148246765\n",
      "Epoch: 449 - loss: 0.5003318786621094 - val loss: 0.5747147798538208\n",
      "Epoch: 450 - loss: 0.5004844069480896 - val loss: 0.5745990872383118\n",
      "Epoch: 451 - loss: 0.5001628398895264 - val loss: 0.574637234210968\n",
      "Epoch: 452 - loss: 0.5004613399505615 - val loss: 0.5746880173683167\n",
      "Epoch: 453 - loss: 0.500031590461731 - val loss: 0.5744431018829346\n",
      "Epoch: 454 - loss: 0.5001611709594727 - val loss: 0.5738118290901184\n",
      "Epoch: 455 - loss: 0.5001848340034485 - val loss: 0.5740161538124084\n",
      "Epoch: 456 - loss: 0.5004537105560303 - val loss: 0.5742815732955933\n",
      "Epoch: 457 - loss: 0.5016174912452698 - val loss: 0.5703821182250977\n",
      "Epoch: 458 - loss: 0.49907442927360535 - val loss: 0.5734923481941223\n",
      "Epoch: 459 - loss: 0.49933043122291565 - val loss: 0.5729566812515259\n",
      "Epoch: 460 - loss: 0.49919554591178894 - val loss: 0.5729620456695557\n",
      "Epoch: 461 - loss: 0.49887964129447937 - val loss: 0.5741353034973145\n",
      "Epoch: 462 - loss: 0.4996071755886078 - val loss: 0.5764016509056091\n",
      "Epoch: 463 - loss: 0.49991798400878906 - val loss: 0.5745851993560791\n",
      "Epoch: 464 - loss: 0.49946528673171997 - val loss: 0.5750160217285156\n",
      "Epoch: 465 - loss: 0.4993889629840851 - val loss: 0.5722569227218628\n",
      "Epoch: 466 - loss: 0.4989871084690094 - val loss: 0.5725250244140625\n",
      "Epoch: 467 - loss: 0.4988461136817932 - val loss: 0.5736178755760193\n",
      "Epoch: 468 - loss: 0.4988885223865509 - val loss: 0.5743483901023865\n",
      "Epoch: 469 - loss: 0.4985317289829254 - val loss: 0.5730302333831787\n",
      "Epoch: 470 - loss: 0.49870434403419495 - val loss: 0.5739107131958008\n",
      "Epoch: 471 - loss: 0.4986439049243927 - val loss: 0.5731738209724426\n",
      "Epoch: 472 - loss: 0.4983409643173218 - val loss: 0.5740525126457214\n",
      "Epoch: 473 - loss: 0.4985876679420471 - val loss: 0.570827841758728\n",
      "Epoch: 474 - loss: 0.49798497557640076 - val loss: 0.5737078785896301\n",
      "Epoch: 475 - loss: 0.49841272830963135 - val loss: 0.5730589032173157\n",
      "Epoch: 476 - loss: 0.4983634352684021 - val loss: 0.5720617175102234\n",
      "Epoch: 477 - loss: 0.49789226055145264 - val loss: 0.5730820298194885\n",
      "Epoch: 478 - loss: 0.49802982807159424 - val loss: 0.5722190737724304\n",
      "Epoch: 479 - loss: 0.49810418486595154 - val loss: 0.5735985636711121\n",
      "Epoch: 480 - loss: 0.497921884059906 - val loss: 0.5704061985015869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 481 - loss: 0.49701988697052 - val loss: 0.57159823179245\n",
      "Epoch: 482 - loss: 0.49745213985443115 - val loss: 0.5727750062942505\n",
      "Epoch: 483 - loss: 0.49796271324157715 - val loss: 0.5706468224525452\n",
      "Epoch: 484 - loss: 0.49707305431365967 - val loss: 0.571935772895813\n",
      "Epoch: 485 - loss: 0.49786147475242615 - val loss: 0.5690455436706543\n",
      "Epoch: 486 - loss: 0.49739760160446167 - val loss: 0.5744540095329285\n",
      "Epoch: 487 - loss: 0.4983966052532196 - val loss: 0.5744167566299438\n",
      "Epoch: 488 - loss: 0.4979715645313263 - val loss: 0.569561779499054\n",
      "Epoch: 489 - loss: 0.49664390087127686 - val loss: 0.5707952380180359\n",
      "Epoch: 490 - loss: 0.4966282248497009 - val loss: 0.5715231895446777\n",
      "Epoch: 491 - loss: 0.49718937277793884 - val loss: 0.5699900388717651\n",
      "Epoch: 492 - loss: 0.4964349865913391 - val loss: 0.5710732936859131\n",
      "Epoch: 493 - loss: 0.4963509142398834 - val loss: 0.5692489147186279\n",
      "Epoch: 494 - loss: 0.496379554271698 - val loss: 0.5698548555374146\n",
      "Epoch: 495 - loss: 0.49592018127441406 - val loss: 0.5712435245513916\n",
      "Epoch: 496 - loss: 0.4965441823005676 - val loss: 0.571719229221344\n",
      "Epoch: 497 - loss: 0.49634960293769836 - val loss: 0.5712087750434875\n",
      "Epoch: 498 - loss: 0.496080607175827 - val loss: 0.5682169795036316\n",
      "Epoch: 499 - loss: 0.49575552344322205 - val loss: 0.5706490874290466\n",
      "Epoch: 500 - loss: 0.49564287066459656 - val loss: 0.5693594813346863\n",
      "Epoch: 501 - loss: 0.49612680077552795 - val loss: 0.5736373662948608\n",
      "Epoch: 502 - loss: 0.49634355306625366 - val loss: 0.5691756010055542\n",
      "Epoch: 503 - loss: 0.49566447734832764 - val loss: 0.5716922879219055\n",
      "Epoch: 504 - loss: 0.49571600556373596 - val loss: 0.5695282220840454\n",
      "Epoch: 505 - loss: 0.4951804578304291 - val loss: 0.5708383917808533\n",
      "Epoch: 506 - loss: 0.4956147074699402 - val loss: 0.572086751461029\n",
      "Epoch: 507 - loss: 0.4951483905315399 - val loss: 0.5686509609222412\n",
      "Epoch: 508 - loss: 0.4950198233127594 - val loss: 0.5690979957580566\n",
      "Epoch: 509 - loss: 0.4951326549053192 - val loss: 0.5694311261177063\n",
      "Epoch: 510 - loss: 0.49504315853118896 - val loss: 0.5685515999794006\n",
      "Epoch: 511 - loss: 0.49492475390434265 - val loss: 0.5691822171211243\n",
      "Epoch: 512 - loss: 0.4956521987915039 - val loss: 0.5689836740493774\n",
      "Epoch: 513 - loss: 0.4950266182422638 - val loss: 0.569890022277832\n",
      "Epoch: 514 - loss: 0.49467137455940247 - val loss: 0.5678508877754211\n",
      "Epoch: 515 - loss: 0.49528446793556213 - val loss: 0.5686500668525696\n",
      "Epoch: 516 - loss: 0.4945741295814514 - val loss: 0.568576991558075\n",
      "Epoch: 517 - loss: 0.49485328793525696 - val loss: 0.5681578516960144\n",
      "Epoch: 518 - loss: 0.49439314007759094 - val loss: 0.566760241985321\n",
      "Epoch: 519 - loss: 0.49551570415496826 - val loss: 0.5712640881538391\n",
      "Epoch: 520 - loss: 0.4945331811904907 - val loss: 0.568946361541748\n",
      "Epoch: 521 - loss: 0.4939832091331482 - val loss: 0.5683501958847046\n",
      "Epoch: 522 - loss: 0.4942016899585724 - val loss: 0.5678243637084961\n",
      "Epoch: 523 - loss: 0.4947856664657593 - val loss: 0.5684741735458374\n",
      "Epoch: 524 - loss: 0.49421370029449463 - val loss: 0.5689363479614258\n",
      "Epoch: 525 - loss: 0.4941047132015228 - val loss: 0.5696775913238525\n",
      "Epoch: 526 - loss: 0.4945158064365387 - val loss: 0.5688591599464417\n",
      "Epoch: 527 - loss: 0.49440911412239075 - val loss: 0.5679893493652344\n",
      "Epoch: 528 - loss: 0.4937892556190491 - val loss: 0.56791090965271\n",
      "Epoch: 529 - loss: 0.49374687671661377 - val loss: 0.5687612295150757\n",
      "Epoch: 530 - loss: 0.49458590149879456 - val loss: 0.5671093463897705\n",
      "Epoch: 531 - loss: 0.49406054615974426 - val loss: 0.567727267742157\n",
      "Epoch: 532 - loss: 0.49346065521240234 - val loss: 0.5668830871582031\n",
      "Epoch: 533 - loss: 0.4950294494628906 - val loss: 0.5684604048728943\n",
      "Epoch: 534 - loss: 0.493891179561615 - val loss: 0.5685147643089294\n",
      "Epoch: 535 - loss: 0.49327242374420166 - val loss: 0.5674296617507935\n",
      "Epoch: 536 - loss: 0.4933086037635803 - val loss: 0.5681237578392029\n",
      "Epoch: 537 - loss: 0.4932645559310913 - val loss: 0.566629946231842\n",
      "Epoch: 538 - loss: 0.49410954117774963 - val loss: 0.5668917298316956\n",
      "Epoch: 539 - loss: 0.4934053122997284 - val loss: 0.5682041645050049\n",
      "Epoch: 540 - loss: 0.49289223551750183 - val loss: 0.5666276812553406\n",
      "Epoch: 541 - loss: 0.4935332238674164 - val loss: 0.566641628742218\n",
      "Epoch: 542 - loss: 0.4934624135494232 - val loss: 0.5665931105613708\n",
      "Epoch: 543 - loss: 0.49363991618156433 - val loss: 0.5667558312416077\n",
      "Epoch: 544 - loss: 0.4940938651561737 - val loss: 0.5671958327293396\n",
      "Epoch: 545 - loss: 0.49274978041648865 - val loss: 0.5681570172309875\n",
      "Epoch: 546 - loss: 0.492939829826355 - val loss: 0.569116473197937\n",
      "Epoch: 547 - loss: 0.49445632100105286 - val loss: 0.5683252215385437\n",
      "Epoch: 548 - loss: 0.4926818311214447 - val loss: 0.5697245001792908\n",
      "Epoch: 549 - loss: 0.4937072694301605 - val loss: 0.5652579069137573\n",
      "Epoch: 550 - loss: 0.49248018860816956 - val loss: 0.567260205745697\n",
      "Epoch: 551 - loss: 0.4922996163368225 - val loss: 0.5669475793838501\n",
      "Epoch: 552 - loss: 0.4926226735115051 - val loss: 0.5676635503768921\n",
      "Epoch: 553 - loss: 0.49208658933639526 - val loss: 0.5682822465896606\n",
      "Epoch: 554 - loss: 0.491759330034256 - val loss: 0.5671844482421875\n",
      "Epoch: 555 - loss: 0.49263083934783936 - val loss: 0.5685388445854187\n",
      "Epoch: 556 - loss: 0.4933185577392578 - val loss: 0.5654159188270569\n",
      "Epoch: 557 - loss: 0.4924198389053345 - val loss: 0.5660101175308228\n",
      "Epoch: 558 - loss: 0.4923035204410553 - val loss: 0.567440390586853\n",
      "Epoch: 559 - loss: 0.4924923777580261 - val loss: 0.5651561617851257\n",
      "Epoch: 560 - loss: 0.4918859004974365 - val loss: 0.5676986575126648\n",
      "Epoch: 561 - loss: 0.4918123185634613 - val loss: 0.5669233798980713\n",
      "Epoch: 562 - loss: 0.49210548400878906 - val loss: 0.5677018165588379\n",
      "Epoch: 563 - loss: 0.49132025241851807 - val loss: 0.5658186078071594\n",
      "Epoch: 564 - loss: 0.49240100383758545 - val loss: 0.5654512643814087\n",
      "Epoch: 565 - loss: 0.4918082058429718 - val loss: 0.5685045123100281\n",
      "Epoch: 566 - loss: 0.4916929304599762 - val loss: 0.5659170150756836\n",
      "Epoch: 567 - loss: 0.4915989637374878 - val loss: 0.5668370127677917\n",
      "Epoch: 568 - loss: 0.491472452878952 - val loss: 0.5688747763633728\n",
      "Epoch: 569 - loss: 0.4926324188709259 - val loss: 0.5662556290626526\n",
      "Epoch: 570 - loss: 0.49170753359794617 - val loss: 0.5655426979064941\n",
      "Epoch: 571 - loss: 0.49105122685432434 - val loss: 0.5687204003334045\n",
      "Epoch: 572 - loss: 0.4926057755947113 - val loss: 0.5648581385612488\n",
      "Epoch: 573 - loss: 0.492031991481781 - val loss: 0.564329206943512\n",
      "Epoch: 574 - loss: 0.4911147952079773 - val loss: 0.5644784569740295\n",
      "Epoch: 575 - loss: 0.4913959503173828 - val loss: 0.5640773177146912\n",
      "Epoch: 576 - loss: 0.49127310514450073 - val loss: 0.5671756863594055\n",
      "Epoch: 577 - loss: 0.4909844696521759 - val loss: 0.567419171333313\n",
      "Epoch: 578 - loss: 0.4921053946018219 - val loss: 0.5644271969795227\n",
      "Epoch: 579 - loss: 0.4910459816455841 - val loss: 0.5648018717765808\n",
      "Epoch: 580 - loss: 0.4913240969181061 - val loss: 0.5656983256340027\n",
      "Epoch: 581 - loss: 0.49247685074806213 - val loss: 0.565622866153717\n",
      "Epoch: 582 - loss: 0.49124833941459656 - val loss: 0.5638300180435181\n",
      "Epoch: 583 - loss: 0.49067384004592896 - val loss: 0.5650774836540222\n",
      "Epoch: 584 - loss: 0.4910178780555725 - val loss: 0.5663584470748901\n",
      "Epoch: 585 - loss: 0.4910462498664856 - val loss: 0.5653427243232727\n",
      "Epoch: 586 - loss: 0.49082469940185547 - val loss: 0.5666894912719727\n",
      "Epoch: 587 - loss: 0.4915475845336914 - val loss: 0.5651365518569946\n",
      "Epoch: 588 - loss: 0.49105170369148254 - val loss: 0.5642198920249939\n",
      "Epoch: 589 - loss: 0.49164849519729614 - val loss: 0.5644044280052185\n",
      "Epoch: 590 - loss: 0.49097904562950134 - val loss: 0.5643484592437744\n",
      "Epoch: 591 - loss: 0.49063965678215027 - val loss: 0.5647789239883423\n",
      "Epoch: 592 - loss: 0.4909416735172272 - val loss: 0.5641763806343079\n",
      "Epoch: 593 - loss: 0.49047914147377014 - val loss: 0.56353360414505\n",
      "Epoch: 594 - loss: 0.49072691798210144 - val loss: 0.5639637112617493\n",
      "Epoch: 595 - loss: 0.49056294560432434 - val loss: 0.5668609142303467\n",
      "Epoch: 596 - loss: 0.49116891622543335 - val loss: 0.5636507272720337\n",
      "Epoch: 597 - loss: 0.49055731296539307 - val loss: 0.5645315051078796\n",
      "Epoch: 598 - loss: 0.490604966878891 - val loss: 0.5650612711906433\n",
      "Epoch: 599 - loss: 0.4900338351726532 - val loss: 0.5635882616043091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 600 - loss: 0.4905746579170227 - val loss: 0.5625706911087036\n",
      "Epoch: 601 - loss: 0.49066483974456787 - val loss: 0.5640580058097839\n",
      "Epoch: 602 - loss: 0.4910518229007721 - val loss: 0.5644656419754028\n",
      "Epoch: 603 - loss: 0.4913097321987152 - val loss: 0.565102756023407\n",
      "Epoch: 604 - loss: 0.49138209223747253 - val loss: 0.5648853182792664\n",
      "Epoch: 605 - loss: 0.49043622612953186 - val loss: 0.5640375018119812\n",
      "Epoch: 606 - loss: 0.4899921119213104 - val loss: 0.5631625652313232\n",
      "Epoch: 607 - loss: 0.4901605546474457 - val loss: 0.5645331144332886\n",
      "Epoch: 608 - loss: 0.49013373255729675 - val loss: 0.564435601234436\n",
      "Epoch: 609 - loss: 0.4910995662212372 - val loss: 0.5633825063705444\n",
      "Epoch: 610 - loss: 0.48947057127952576 - val loss: 0.5630766153335571\n",
      "Epoch: 611 - loss: 0.49007338285446167 - val loss: 0.5640974640846252\n",
      "Epoch: 612 - loss: 0.48973751068115234 - val loss: 0.5631048083305359\n",
      "Epoch: 613 - loss: 0.4899410307407379 - val loss: 0.5633941292762756\n",
      "Epoch: 614 - loss: 0.49019140005111694 - val loss: 0.5624077320098877\n",
      "Epoch: 615 - loss: 0.48957687616348267 - val loss: 0.5641125440597534\n",
      "Epoch: 616 - loss: 0.48942381143569946 - val loss: 0.5657561421394348\n",
      "Epoch: 617 - loss: 0.49082812666893005 - val loss: 0.5628688335418701\n",
      "Epoch: 618 - loss: 0.4899035096168518 - val loss: 0.5640483498573303\n",
      "Epoch: 619 - loss: 0.48981863260269165 - val loss: 0.5638206005096436\n",
      "Epoch: 620 - loss: 0.4892879128456116 - val loss: 0.5629141926765442\n",
      "Epoch: 621 - loss: 0.4895338714122772 - val loss: 0.562575101852417\n",
      "Epoch: 622 - loss: 0.4893893301486969 - val loss: 0.5617624521255493\n",
      "Epoch: 623 - loss: 0.48924729228019714 - val loss: 0.5638338923454285\n",
      "Epoch: 624 - loss: 0.4893335700035095 - val loss: 0.5647052526473999\n",
      "Epoch: 625 - loss: 0.4889080226421356 - val loss: 0.5628439784049988\n",
      "Epoch: 626 - loss: 0.4888259470462799 - val loss: 0.5644491910934448\n",
      "Epoch: 627 - loss: 0.48940083384513855 - val loss: 0.5622326731681824\n",
      "Epoch: 628 - loss: 0.4890560209751129 - val loss: 0.561678409576416\n",
      "Epoch: 629 - loss: 0.4889560043811798 - val loss: 0.561168372631073\n",
      "Epoch: 630 - loss: 0.4889918863773346 - val loss: 0.5642626881599426\n",
      "Epoch: 631 - loss: 0.4892443120479584 - val loss: 0.5654749274253845\n",
      "Epoch: 632 - loss: 0.4891650080680847 - val loss: 0.5639951825141907\n",
      "Epoch: 633 - loss: 0.4886554479598999 - val loss: 0.5656836628913879\n",
      "Epoch: 634 - loss: 0.4897601306438446 - val loss: 0.5625408291816711\n",
      "Epoch: 635 - loss: 0.4887768030166626 - val loss: 0.5631201863288879\n",
      "Epoch: 636 - loss: 0.48854154348373413 - val loss: 0.5638405084609985\n",
      "Epoch: 637 - loss: 0.4887588322162628 - val loss: 0.5628116130828857\n",
      "Epoch: 638 - loss: 0.4887562096118927 - val loss: 0.5643582940101624\n",
      "Epoch: 639 - loss: 0.48929938673973083 - val loss: 0.5635591745376587\n",
      "Epoch: 640 - loss: 0.48857128620147705 - val loss: 0.5623793005943298\n",
      "Epoch: 641 - loss: 0.4882248640060425 - val loss: 0.5641428232192993\n",
      "Epoch: 642 - loss: 0.48868682980537415 - val loss: 0.5625563263893127\n",
      "Epoch: 643 - loss: 0.4885823726654053 - val loss: 0.5619146823883057\n",
      "Epoch: 644 - loss: 0.4879251718521118 - val loss: 0.5627644062042236\n",
      "Epoch: 645 - loss: 0.4880884289741516 - val loss: 0.5629193186759949\n",
      "Epoch: 646 - loss: 0.4888848066329956 - val loss: 0.5640413165092468\n",
      "Epoch: 647 - loss: 0.4879877269268036 - val loss: 0.5632328987121582\n",
      "Epoch: 648 - loss: 0.4878107011318207 - val loss: 0.5628576874732971\n",
      "Epoch: 649 - loss: 0.4882345497608185 - val loss: 0.5623658895492554\n",
      "Epoch: 650 - loss: 0.4879537522792816 - val loss: 0.5624804496765137\n",
      "Epoch: 651 - loss: 0.4881019592285156 - val loss: 0.5615091919898987\n",
      "Epoch: 652 - loss: 0.4877340495586395 - val loss: 0.5631659626960754\n",
      "Epoch: 653 - loss: 0.48765477538108826 - val loss: 0.562091052532196\n",
      "Epoch: 654 - loss: 0.4877597987651825 - val loss: 0.5614765286445618\n",
      "Epoch: 655 - loss: 0.48822787404060364 - val loss: 0.5633190274238586\n",
      "Epoch: 656 - loss: 0.4878704249858856 - val loss: 0.5636361837387085\n",
      "Epoch: 657 - loss: 0.48768919706344604 - val loss: 0.5642716288566589\n",
      "Epoch: 658 - loss: 0.4887816905975342 - val loss: 0.5645545721054077\n",
      "Epoch: 659 - loss: 0.48825544118881226 - val loss: 0.5642193555831909\n",
      "Epoch: 660 - loss: 0.4889477491378784 - val loss: 0.5641382336616516\n",
      "Epoch: 661 - loss: 0.48776355385780334 - val loss: 0.5641076564788818\n",
      "Epoch: 662 - loss: 0.4877346456050873 - val loss: 0.5647125244140625\n",
      "Epoch: 663 - loss: 0.4882354140281677 - val loss: 0.5622091889381409\n",
      "Epoch: 664 - loss: 0.4879244267940521 - val loss: 0.5626977682113647\n",
      "Epoch: 665 - loss: 0.488442987203598 - val loss: 0.562907874584198\n",
      "Epoch: 666 - loss: 0.48718956112861633 - val loss: 0.5633590817451477\n",
      "Epoch: 667 - loss: 0.4872957766056061 - val loss: 0.5617940425872803\n",
      "Epoch: 668 - loss: 0.48659712076187134 - val loss: 0.5611361265182495\n",
      "Epoch: 669 - loss: 0.4874303340911865 - val loss: 0.561674952507019\n",
      "Epoch: 670 - loss: 0.48746469616889954 - val loss: 0.5622280240058899\n",
      "Epoch: 671 - loss: 0.48693373799324036 - val loss: 0.56243896484375\n",
      "Epoch: 672 - loss: 0.4870298504829407 - val loss: 0.5646086931228638\n",
      "Epoch: 673 - loss: 0.4872291386127472 - val loss: 0.5639980435371399\n",
      "Epoch: 674 - loss: 0.4878561198711395 - val loss: 0.5623310208320618\n",
      "Epoch: 675 - loss: 0.48647236824035645 - val loss: 0.5643860697746277\n",
      "Epoch: 676 - loss: 0.4872667193412781 - val loss: 0.5648984909057617\n",
      "Epoch: 677 - loss: 0.4870116710662842 - val loss: 0.5636247396469116\n",
      "Epoch: 678 - loss: 0.48680129647254944 - val loss: 0.5621716380119324\n",
      "Epoch: 679 - loss: 0.4869399964809418 - val loss: 0.5629971027374268\n",
      "Epoch: 680 - loss: 0.4862849712371826 - val loss: 0.5633675456047058\n",
      "Epoch: 681 - loss: 0.4865357577800751 - val loss: 0.5621165037155151\n",
      "Epoch: 682 - loss: 0.4864507019519806 - val loss: 0.5635765194892883\n",
      "Epoch: 683 - loss: 0.4866744577884674 - val loss: 0.5613422989845276\n",
      "Epoch: 684 - loss: 0.4863477945327759 - val loss: 0.5640074014663696\n",
      "Epoch: 685 - loss: 0.4866505265235901 - val loss: 0.5634140968322754\n",
      "Epoch: 686 - loss: 0.4867061674594879 - val loss: 0.5614234805107117\n",
      "Epoch: 687 - loss: 0.4860668182373047 - val loss: 0.5616798996925354\n",
      "Epoch: 688 - loss: 0.4861665666103363 - val loss: 0.5625139474868774\n",
      "Epoch: 689 - loss: 0.48682859539985657 - val loss: 0.5620061159133911\n",
      "Epoch: 690 - loss: 0.48643550276756287 - val loss: 0.5631247162818909\n",
      "Epoch: 691 - loss: 0.48581960797309875 - val loss: 0.5627157688140869\n",
      "Epoch: 692 - loss: 0.4862547218799591 - val loss: 0.563135027885437\n",
      "Epoch: 693 - loss: 0.4860559105873108 - val loss: 0.5635383129119873\n",
      "Epoch: 694 - loss: 0.4861680865287781 - val loss: 0.5624962449073792\n",
      "Epoch: 695 - loss: 0.4861479699611664 - val loss: 0.561367928981781\n",
      "Epoch: 696 - loss: 0.4856334328651428 - val loss: 0.5630426406860352\n",
      "Epoch: 697 - loss: 0.4858667552471161 - val loss: 0.5604971647262573\n",
      "Epoch: 698 - loss: 0.4861077070236206 - val loss: 0.561776340007782\n",
      "Epoch: 699 - loss: 0.4859429597854614 - val loss: 0.5636756420135498\n",
      "Epoch: 700 - loss: 0.4859791398048401 - val loss: 0.5622347593307495\n",
      "Epoch: 701 - loss: 0.4863029420375824 - val loss: 0.5628319382667542\n",
      "Epoch: 702 - loss: 0.48570895195007324 - val loss: 0.5615633130073547\n",
      "Epoch: 703 - loss: 0.48618200421333313 - val loss: 0.5594215393066406\n",
      "Epoch: 704 - loss: 0.48618510365486145 - val loss: 0.5604110360145569\n",
      "Epoch: 705 - loss: 0.48539212346076965 - val loss: 0.5596101880073547\n",
      "Epoch: 706 - loss: 0.4850509464740753 - val loss: 0.561363935470581\n",
      "Epoch: 707 - loss: 0.4850844144821167 - val loss: 0.5635074973106384\n",
      "Epoch: 708 - loss: 0.4848299026489258 - val loss: 0.5625115036964417\n",
      "Epoch: 709 - loss: 0.48502564430236816 - val loss: 0.563447892665863\n",
      "Epoch: 710 - loss: 0.48503604531288147 - val loss: 0.562420666217804\n",
      "Epoch: 711 - loss: 0.48487967252731323 - val loss: 0.5625645518302917\n",
      "Epoch: 712 - loss: 0.4849730134010315 - val loss: 0.5607690215110779\n",
      "Epoch: 713 - loss: 0.48440420627593994 - val loss: 0.5630790591239929\n",
      "Epoch: 714 - loss: 0.4845227897167206 - val loss: 0.5617409944534302\n",
      "Epoch: 715 - loss: 0.48467686772346497 - val loss: 0.5626657605171204\n",
      "Epoch: 716 - loss: 0.4848911166191101 - val loss: 0.5623087882995605\n",
      "Epoch: 717 - loss: 0.4846647381782532 - val loss: 0.5633783936500549\n",
      "Epoch: 718 - loss: 0.4847172200679779 - val loss: 0.5628549456596375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 719 - loss: 0.4848114550113678 - val loss: 0.5617040991783142\n",
      "Epoch: 720 - loss: 0.48472344875335693 - val loss: 0.5618671774864197\n",
      "Epoch: 721 - loss: 0.48433011770248413 - val loss: 0.5634036064147949\n",
      "Epoch: 722 - loss: 0.48416993021965027 - val loss: 0.5626177787780762\n",
      "Epoch: 723 - loss: 0.4848422110080719 - val loss: 0.5632941722869873\n",
      "Epoch: 724 - loss: 0.4838466942310333 - val loss: 0.5653904676437378\n",
      "Epoch: 725 - loss: 0.48453694581985474 - val loss: 0.5637677311897278\n",
      "Epoch: 726 - loss: 0.48401859402656555 - val loss: 0.5630796551704407\n",
      "Epoch: 727 - loss: 0.48457521200180054 - val loss: 0.5627955794334412\n",
      "Epoch: 728 - loss: 0.48448696732521057 - val loss: 0.56276535987854\n",
      "Epoch: 729 - loss: 0.48485785722732544 - val loss: 0.5617749094963074\n",
      "Epoch: 730 - loss: 0.4843849241733551 - val loss: 0.5629785656929016\n",
      "Epoch: 731 - loss: 0.4836250841617584 - val loss: 0.5615133047103882\n",
      "Epoch: 732 - loss: 0.4845007061958313 - val loss: 0.5626646280288696\n",
      "Epoch: 733 - loss: 0.48423877358436584 - val loss: 0.5622426271438599\n",
      "Epoch: 734 - loss: 0.48369845747947693 - val loss: 0.5623216032981873\n",
      "Epoch: 735 - loss: 0.4837642014026642 - val loss: 0.5618457198143005\n",
      "Epoch: 736 - loss: 0.48342299461364746 - val loss: 0.563498854637146\n",
      "Epoch: 737 - loss: 0.4833279848098755 - val loss: 0.5630422234535217\n",
      "Epoch: 738 - loss: 0.4839836061000824 - val loss: 0.5618317127227783\n",
      "Epoch: 739 - loss: 0.48397374153137207 - val loss: 0.5624954700469971\n",
      "Epoch: 740 - loss: 0.48284924030303955 - val loss: 0.5628337264060974\n",
      "Epoch: 741 - loss: 0.48339933156967163 - val loss: 0.5638181567192078\n",
      "Epoch: 742 - loss: 0.4841979146003723 - val loss: 0.5634891986846924\n",
      "Epoch: 743 - loss: 0.48349136114120483 - val loss: 0.5633171796798706\n",
      "Epoch: 744 - loss: 0.48404085636138916 - val loss: 0.5635397434234619\n",
      "Epoch: 745 - loss: 0.48335811495780945 - val loss: 0.5621426105499268\n",
      "Epoch: 746 - loss: 0.48394522070884705 - val loss: 0.5631455779075623\n",
      "Epoch: 747 - loss: 0.48391759395599365 - val loss: 0.5617996454238892\n",
      "Epoch: 748 - loss: 0.48331230878829956 - val loss: 0.5643832683563232\n",
      "Epoch: 749 - loss: 0.48409271240234375 - val loss: 0.5618274211883545\n",
      "Epoch: 750 - loss: 0.48296937346458435 - val loss: 0.5651443600654602\n",
      "Epoch: 751 - loss: 0.4832593500614166 - val loss: 0.5641556978225708\n",
      "Epoch: 752 - loss: 0.4832383990287781 - val loss: 0.5634929537773132\n",
      "Epoch: 753 - loss: 0.48298293352127075 - val loss: 0.5632683038711548\n",
      "Epoch: 754 - loss: 0.4838446080684662 - val loss: 0.5633531808853149\n",
      "Epoch: 755 - loss: 0.4826119840145111 - val loss: 0.563005805015564\n",
      "Epoch: 756 - loss: 0.4828188121318817 - val loss: 0.5625243782997131\n",
      "Epoch: 757 - loss: 0.4828820824623108 - val loss: 0.5608344078063965\n",
      "Epoch: 758 - loss: 0.48287835717201233 - val loss: 0.564557671546936\n",
      "Epoch: 759 - loss: 0.48304253816604614 - val loss: 0.5620532631874084\n",
      "Epoch: 760 - loss: 0.4820863902568817 - val loss: 0.5623639822006226\n",
      "Epoch: 761 - loss: 0.48270460963249207 - val loss: 0.5638318657875061\n",
      "Epoch: 762 - loss: 0.4823763072490692 - val loss: 0.566685676574707\n",
      "Epoch: 763 - loss: 0.48271822929382324 - val loss: 0.5643438696861267\n",
      "Epoch: 764 - loss: 0.48329514265060425 - val loss: 0.5628911852836609\n",
      "Epoch: 765 - loss: 0.4831911027431488 - val loss: 0.5629083514213562\n",
      "Epoch: 766 - loss: 0.4829323887825012 - val loss: 0.5614337921142578\n",
      "Epoch: 767 - loss: 0.48321717977523804 - val loss: 0.5634292364120483\n",
      "Epoch: 768 - loss: 0.4818929433822632 - val loss: 0.5629730820655823\n",
      "Epoch: 769 - loss: 0.48255160450935364 - val loss: 0.5623562335968018\n",
      "Epoch: 770 - loss: 0.4825088083744049 - val loss: 0.5628006458282471\n",
      "Epoch: 771 - loss: 0.4820477068424225 - val loss: 0.5629671216011047\n",
      "Epoch: 772 - loss: 0.48205482959747314 - val loss: 0.5634000897407532\n",
      "Epoch: 773 - loss: 0.48253172636032104 - val loss: 0.5638038516044617\n",
      "Epoch: 774 - loss: 0.4821614921092987 - val loss: 0.5605679750442505\n",
      "Epoch: 775 - loss: 0.48304206132888794 - val loss: 0.562177300453186\n",
      "Epoch: 776 - loss: 0.4823973774909973 - val loss: 0.5624545812606812\n",
      "Epoch: 777 - loss: 0.4825001358985901 - val loss: 0.5618233680725098\n",
      "Epoch: 778 - loss: 0.48207610845565796 - val loss: 0.5632068514823914\n",
      "Epoch: 779 - loss: 0.4827502369880676 - val loss: 0.5623419880867004\n",
      "Epoch: 780 - loss: 0.4817140996456146 - val loss: 0.5627673864364624\n",
      "Epoch: 781 - loss: 0.4815065562725067 - val loss: 0.5637173056602478\n",
      "Epoch: 782 - loss: 0.4816688895225525 - val loss: 0.5622321963310242\n",
      "Epoch: 783 - loss: 0.48129430413246155 - val loss: 0.5640127062797546\n",
      "Epoch: 784 - loss: 0.4813385605812073 - val loss: 0.5621863007545471\n",
      "Epoch: 785 - loss: 0.4820736348628998 - val loss: 0.5606881976127625\n",
      "Epoch: 786 - loss: 0.4819411635398865 - val loss: 0.5627376437187195\n",
      "Epoch: 787 - loss: 0.4820166528224945 - val loss: 0.5608729720115662\n",
      "Epoch: 788 - loss: 0.482361763715744 - val loss: 0.5591788291931152\n",
      "Epoch: 789 - loss: 0.4814510643482208 - val loss: 0.561829686164856\n",
      "Epoch: 790 - loss: 0.4815197288990021 - val loss: 0.5592674016952515\n",
      "Epoch: 791 - loss: 0.4809836447238922 - val loss: 0.5588604807853699\n",
      "Epoch: 792 - loss: 0.4807087182998657 - val loss: 0.5593705773353577\n",
      "Epoch: 793 - loss: 0.4810202419757843 - val loss: 0.5596808195114136\n",
      "Epoch: 794 - loss: 0.48072853684425354 - val loss: 0.5603566765785217\n",
      "Epoch: 795 - loss: 0.48127955198287964 - val loss: 0.5594260692596436\n",
      "Epoch: 796 - loss: 0.48079073429107666 - val loss: 0.5606887340545654\n",
      "Epoch: 797 - loss: 0.4805818796157837 - val loss: 0.5621298551559448\n",
      "Epoch: 798 - loss: 0.4808325469493866 - val loss: 0.5609608888626099\n",
      "Epoch: 799 - loss: 0.48079490661621094 - val loss: 0.5594782829284668\n",
      "Epoch: 800 - loss: 0.4808112680912018 - val loss: 0.5601561665534973\n",
      "Epoch: 801 - loss: 0.48130908608436584 - val loss: 0.5603172183036804\n",
      "Epoch: 802 - loss: 0.48052138090133667 - val loss: 0.5598939657211304\n",
      "Epoch: 803 - loss: 0.48088395595550537 - val loss: 0.5605272650718689\n",
      "Epoch: 804 - loss: 0.4805747866630554 - val loss: 0.5580317974090576\n",
      "Epoch: 805 - loss: 0.4806639552116394 - val loss: 0.5589303374290466\n",
      "Epoch: 806 - loss: 0.48046764731407166 - val loss: 0.5589963793754578\n",
      "Epoch: 807 - loss: 0.4803140163421631 - val loss: 0.5581562519073486\n",
      "Epoch: 808 - loss: 0.4806677997112274 - val loss: 0.558784008026123\n",
      "Epoch: 809 - loss: 0.4796980917453766 - val loss: 0.5584567189216614\n",
      "Epoch: 810 - loss: 0.48061785101890564 - val loss: 0.5586028099060059\n",
      "Epoch: 811 - loss: 0.4806099534034729 - val loss: 0.559332013130188\n",
      "Epoch: 812 - loss: 0.48022010922431946 - val loss: 0.5613588094711304\n",
      "Epoch: 813 - loss: 0.48166272044181824 - val loss: 0.5582980513572693\n",
      "Epoch: 814 - loss: 0.4801023006439209 - val loss: 0.5615267157554626\n",
      "Epoch: 815 - loss: 0.48052680492401123 - val loss: 0.5575993657112122\n",
      "Epoch: 816 - loss: 0.4791366159915924 - val loss: 0.5586835145950317\n",
      "Epoch: 817 - loss: 0.47996294498443604 - val loss: 0.5586252212524414\n",
      "Epoch: 818 - loss: 0.4796915054321289 - val loss: 0.5609548687934875\n",
      "Epoch: 819 - loss: 0.4802786409854889 - val loss: 0.5579952001571655\n",
      "Epoch: 820 - loss: 0.4797092080116272 - val loss: 0.5608617067337036\n",
      "Epoch: 821 - loss: 0.4790879487991333 - val loss: 0.5613214373588562\n",
      "Epoch: 822 - loss: 0.48022693395614624 - val loss: 0.558242917060852\n",
      "Epoch: 823 - loss: 0.47966936230659485 - val loss: 0.5573534369468689\n",
      "Epoch: 824 - loss: 0.4800730049610138 - val loss: 0.5580018758773804\n",
      "Epoch: 825 - loss: 0.4792841374874115 - val loss: 0.5585508942604065\n",
      "Epoch: 826 - loss: 0.4796663224697113 - val loss: 0.5582979321479797\n",
      "Epoch: 827 - loss: 0.47895491123199463 - val loss: 0.5590617060661316\n",
      "Epoch: 828 - loss: 0.47948992252349854 - val loss: 0.558690071105957\n",
      "Epoch: 829 - loss: 0.4792921543121338 - val loss: 0.5599942207336426\n",
      "Epoch: 830 - loss: 0.47939541935920715 - val loss: 0.5603700280189514\n",
      "Epoch: 831 - loss: 0.47839951515197754 - val loss: 0.5604617595672607\n",
      "Epoch: 832 - loss: 0.4789995849132538 - val loss: 0.5623000264167786\n",
      "Epoch: 833 - loss: 0.4797214865684509 - val loss: 0.5593591928482056\n",
      "Epoch: 834 - loss: 0.4797045588493347 - val loss: 0.5609045028686523\n",
      "Epoch: 835 - loss: 0.4790272116661072 - val loss: 0.5616231560707092\n",
      "Epoch: 836 - loss: 0.4784966707229614 - val loss: 0.5601603388786316\n",
      "Epoch: 837 - loss: 0.47929930686950684 - val loss: 0.5610939264297485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 838 - loss: 0.4794350564479828 - val loss: 0.5580634474754333\n",
      "Epoch: 839 - loss: 0.4784400165081024 - val loss: 0.5597252249717712\n",
      "Epoch: 840 - loss: 0.4796716570854187 - val loss: 0.560910165309906\n",
      "Epoch: 841 - loss: 0.47862160205841064 - val loss: 0.5593725442886353\n",
      "Epoch: 842 - loss: 0.47908779978752136 - val loss: 0.5574738383293152\n",
      "Epoch: 843 - loss: 0.47872278094291687 - val loss: 0.5609896779060364\n",
      "Epoch: 844 - loss: 0.4786641001701355 - val loss: 0.5589511394500732\n",
      "Epoch: 845 - loss: 0.4786810576915741 - val loss: 0.5591294169425964\n",
      "Epoch: 846 - loss: 0.47809281945228577 - val loss: 0.5603122115135193\n",
      "Epoch: 847 - loss: 0.4793647527694702 - val loss: 0.5581806302070618\n",
      "Epoch: 848 - loss: 0.47719138860702515 - val loss: 0.5577546954154968\n",
      "Epoch: 849 - loss: 0.4777541756629944 - val loss: 0.557982861995697\n",
      "Epoch: 850 - loss: 0.47802993655204773 - val loss: 0.560425341129303\n",
      "Epoch: 851 - loss: 0.47847089171409607 - val loss: 0.5581309795379639\n",
      "Epoch: 852 - loss: 0.4776388108730316 - val loss: 0.5596787333488464\n",
      "Epoch: 853 - loss: 0.47825542092323303 - val loss: 0.5583921670913696\n",
      "Epoch: 854 - loss: 0.4788716733455658 - val loss: 0.5585095882415771\n",
      "Epoch: 855 - loss: 0.4777439534664154 - val loss: 0.5582903027534485\n",
      "Epoch: 856 - loss: 0.47832468152046204 - val loss: 0.5583096146583557\n",
      "Epoch: 857 - loss: 0.47772449254989624 - val loss: 0.5589545369148254\n",
      "Epoch: 858 - loss: 0.47767794132232666 - val loss: 0.5606294870376587\n",
      "Epoch: 859 - loss: 0.4776912331581116 - val loss: 0.5582442283630371\n",
      "Epoch: 860 - loss: 0.4778123199939728 - val loss: 0.5587415099143982\n",
      "Epoch: 861 - loss: 0.47838857769966125 - val loss: 0.559684693813324\n",
      "Epoch: 862 - loss: 0.4783704876899719 - val loss: 0.558959424495697\n",
      "Epoch: 863 - loss: 0.47829321026802063 - val loss: 0.5582548975944519\n",
      "Epoch: 864 - loss: 0.47800883650779724 - val loss: 0.5599503517150879\n",
      "Epoch: 865 - loss: 0.4783884286880493 - val loss: 0.5577929615974426\n",
      "Epoch: 866 - loss: 0.4774348735809326 - val loss: 0.5568275451660156\n",
      "Epoch: 867 - loss: 0.4770624339580536 - val loss: 0.5595359802246094\n",
      "Epoch: 868 - loss: 0.47741636633872986 - val loss: 0.5581275224685669\n",
      "Epoch: 869 - loss: 0.4779788851737976 - val loss: 0.5566208362579346\n",
      "Epoch: 870 - loss: 0.4772252142429352 - val loss: 0.5591512322425842\n",
      "Epoch: 871 - loss: 0.47791603207588196 - val loss: 0.5584927797317505\n",
      "Epoch: 872 - loss: 0.4770795404911041 - val loss: 0.5598762035369873\n",
      "Epoch: 873 - loss: 0.4778432250022888 - val loss: 0.5576964616775513\n",
      "Epoch: 874 - loss: 0.47692635655403137 - val loss: 0.5583835244178772\n",
      "Epoch: 875 - loss: 0.4769642949104309 - val loss: 0.5597882866859436\n",
      "Epoch: 876 - loss: 0.4772476851940155 - val loss: 0.5593516230583191\n",
      "Epoch: 877 - loss: 0.47718966007232666 - val loss: 0.5577154755592346\n",
      "Epoch: 878 - loss: 0.47740378975868225 - val loss: 0.5564964413642883\n",
      "Epoch: 879 - loss: 0.47632813453674316 - val loss: 0.5577159523963928\n",
      "Epoch: 880 - loss: 0.4777900278568268 - val loss: 0.5588752627372742\n",
      "Epoch: 881 - loss: 0.47803035378456116 - val loss: 0.5573176145553589\n",
      "Epoch: 882 - loss: 0.4771382510662079 - val loss: 0.5590643286705017\n",
      "Epoch: 883 - loss: 0.4782467782497406 - val loss: 0.5603142380714417\n",
      "Epoch: 884 - loss: 0.4770301282405853 - val loss: 0.5589017868041992\n",
      "Epoch: 885 - loss: 0.47781550884246826 - val loss: 0.5580605268478394\n",
      "Epoch: 886 - loss: 0.4767247438430786 - val loss: 0.5577726364135742\n",
      "Epoch: 887 - loss: 0.47715073823928833 - val loss: 0.5581530928611755\n",
      "Epoch: 888 - loss: 0.47751548886299133 - val loss: 0.555904746055603\n",
      "Epoch: 889 - loss: 0.47723010182380676 - val loss: 0.5582807064056396\n",
      "Epoch: 890 - loss: 0.47743862867355347 - val loss: 0.5560005307197571\n",
      "Epoch: 891 - loss: 0.4768698215484619 - val loss: 0.5573862791061401\n",
      "Epoch: 892 - loss: 0.4766564667224884 - val loss: 0.5586600303649902\n",
      "Epoch: 893 - loss: 0.47631070017814636 - val loss: 0.557619035243988\n",
      "Epoch: 894 - loss: 0.47598162293434143 - val loss: 0.5592443943023682\n",
      "Epoch: 895 - loss: 0.47647419571876526 - val loss: 0.5579941272735596\n",
      "Epoch: 896 - loss: 0.47666484117507935 - val loss: 0.5570580363273621\n",
      "Epoch: 897 - loss: 0.47711917757987976 - val loss: 0.5562898516654968\n",
      "Epoch: 898 - loss: 0.4768151044845581 - val loss: 0.5571876764297485\n",
      "Epoch: 899 - loss: 0.4776144325733185 - val loss: 0.5606042146682739\n",
      "Epoch: 900 - loss: 0.47589242458343506 - val loss: 0.560280442237854\n",
      "Epoch: 901 - loss: 0.4769136309623718 - val loss: 0.5566833019256592\n",
      "Epoch: 902 - loss: 0.47599881887435913 - val loss: 0.5583789348602295\n",
      "Epoch: 903 - loss: 0.476664274930954 - val loss: 0.5571811199188232\n",
      "Epoch: 904 - loss: 0.475921630859375 - val loss: 0.5574585199356079\n",
      "Epoch: 905 - loss: 0.47675082087516785 - val loss: 0.5571407675743103\n",
      "Epoch: 906 - loss: 0.47639307379722595 - val loss: 0.557466447353363\n",
      "Epoch: 907 - loss: 0.4772363305091858 - val loss: 0.5569940805435181\n",
      "Epoch: 908 - loss: 0.47567427158355713 - val loss: 0.5575823783874512\n",
      "Epoch: 909 - loss: 0.47653353214263916 - val loss: 0.5585148930549622\n",
      "Epoch: 910 - loss: 0.4765614867210388 - val loss: 0.5563949346542358\n",
      "Epoch: 911 - loss: 0.4763388931751251 - val loss: 0.5564969778060913\n",
      "Epoch: 912 - loss: 0.4757891297340393 - val loss: 0.5565303564071655\n",
      "Epoch: 913 - loss: 0.4767007827758789 - val loss: 0.5572000741958618\n",
      "Epoch: 914 - loss: 0.4768150746822357 - val loss: 0.5577338337898254\n",
      "Epoch: 915 - loss: 0.4778207242488861 - val loss: 0.5588100552558899\n",
      "Epoch: 916 - loss: 0.47764527797698975 - val loss: 0.5604905486106873\n",
      "Epoch: 917 - loss: 0.47535744309425354 - val loss: 0.5572425723075867\n",
      "Epoch: 918 - loss: 0.4763113558292389 - val loss: 0.5569172501564026\n",
      "Epoch: 919 - loss: 0.4758821725845337 - val loss: 0.5574645400047302\n",
      "Epoch: 920 - loss: 0.4766663610935211 - val loss: 0.5570021867752075\n",
      "Epoch: 921 - loss: 0.47597792744636536 - val loss: 0.5567470788955688\n",
      "Epoch: 922 - loss: 0.47607725858688354 - val loss: 0.556667685508728\n",
      "Epoch: 923 - loss: 0.47543856501579285 - val loss: 0.5566900372505188\n",
      "Epoch: 924 - loss: 0.4752088189125061 - val loss: 0.5561730265617371\n",
      "Epoch: 925 - loss: 0.4765322506427765 - val loss: 0.5612676739692688\n",
      "Epoch: 926 - loss: 0.47536712884902954 - val loss: 0.5577568411827087\n",
      "Epoch: 927 - loss: 0.47610172629356384 - val loss: 0.5566262602806091\n",
      "Epoch: 928 - loss: 0.47596457600593567 - val loss: 0.5584710836410522\n",
      "Epoch: 929 - loss: 0.4760822653770447 - val loss: 0.5568729043006897\n",
      "Epoch: 930 - loss: 0.4757782220840454 - val loss: 0.5567116737365723\n",
      "Epoch: 931 - loss: 0.4762255847454071 - val loss: 0.5565089583396912\n",
      "Epoch: 932 - loss: 0.47534865140914917 - val loss: 0.5558225512504578\n",
      "Epoch: 933 - loss: 0.47620686888694763 - val loss: 0.5580917596817017\n",
      "Epoch: 934 - loss: 0.47542068362236023 - val loss: 0.5559790134429932\n",
      "Epoch: 935 - loss: 0.47563910484313965 - val loss: 0.5571317076683044\n",
      "Epoch: 936 - loss: 0.4754887819290161 - val loss: 0.5566433072090149\n",
      "Epoch: 937 - loss: 0.47509121894836426 - val loss: 0.5551032423973083\n",
      "Epoch: 938 - loss: 0.4754926264286041 - val loss: 0.5566942095756531\n",
      "Epoch: 939 - loss: 0.4757395386695862 - val loss: 0.5546913743019104\n",
      "Epoch: 940 - loss: 0.4749070405960083 - val loss: 0.558359682559967\n",
      "Epoch: 941 - loss: 0.47569409012794495 - val loss: 0.5557988286018372\n",
      "Epoch: 942 - loss: 0.4760183095932007 - val loss: 0.5571748614311218\n",
      "Epoch: 943 - loss: 0.47461357712745667 - val loss: 0.5557258725166321\n",
      "Epoch: 944 - loss: 0.4754222333431244 - val loss: 0.556561291217804\n",
      "Epoch: 945 - loss: 0.4749574661254883 - val loss: 0.5564853549003601\n",
      "Epoch: 946 - loss: 0.4747675359249115 - val loss: 0.556654691696167\n",
      "Epoch: 947 - loss: 0.47557052969932556 - val loss: 0.5553674101829529\n",
      "Epoch: 948 - loss: 0.47463658452033997 - val loss: 0.5564485788345337\n",
      "Epoch: 949 - loss: 0.4757816791534424 - val loss: 0.5570513010025024\n",
      "Epoch: 950 - loss: 0.4747506380081177 - val loss: 0.5550205111503601\n",
      "Epoch: 951 - loss: 0.4744037091732025 - val loss: 0.5543171167373657\n",
      "Epoch: 952 - loss: 0.47547394037246704 - val loss: 0.5566924810409546\n",
      "Epoch: 953 - loss: 0.4751380980014801 - val loss: 0.5563935041427612\n",
      "Epoch: 954 - loss: 0.47507792711257935 - val loss: 0.5557212233543396\n",
      "Epoch: 955 - loss: 0.4761844575405121 - val loss: 0.5572186708450317\n",
      "Epoch: 956 - loss: 0.47462737560272217 - val loss: 0.5552325248718262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 957 - loss: 0.47491517663002014 - val loss: 0.5572133660316467\n",
      "Epoch: 958 - loss: 0.4745539724826813 - val loss: 0.5535887479782104\n",
      "Epoch: 959 - loss: 0.47513502836227417 - val loss: 0.5591223835945129\n",
      "Epoch: 960 - loss: 0.47471389174461365 - val loss: 0.5569760203361511\n",
      "Epoch: 961 - loss: 0.4745137095451355 - val loss: 0.5562378168106079\n",
      "Epoch: 962 - loss: 0.475140243768692 - val loss: 0.5591639876365662\n",
      "Epoch: 963 - loss: 0.4744998812675476 - val loss: 0.5561349391937256\n",
      "Epoch: 964 - loss: 0.4757486581802368 - val loss: 0.5574395060539246\n",
      "Epoch: 965 - loss: 0.47423413395881653 - val loss: 0.5542408227920532\n",
      "Epoch: 966 - loss: 0.4752291142940521 - val loss: 0.5574755072593689\n",
      "Epoch: 967 - loss: 0.47407278418540955 - val loss: 0.5549706220626831\n",
      "Epoch: 968 - loss: 0.47383564710617065 - val loss: 0.5555716753005981\n",
      "Epoch: 969 - loss: 0.4746467173099518 - val loss: 0.5577113032341003\n",
      "Epoch: 970 - loss: 0.4747871160507202 - val loss: 0.5566912889480591\n",
      "Epoch: 971 - loss: 0.4745872914791107 - val loss: 0.5563974976539612\n",
      "Epoch: 972 - loss: 0.4747272729873657 - val loss: 0.5555408000946045\n",
      "Epoch: 973 - loss: 0.4744005799293518 - val loss: 0.5536819696426392\n",
      "Epoch: 974 - loss: 0.47402074933052063 - val loss: 0.5557081699371338\n",
      "Epoch: 975 - loss: 0.4739879369735718 - val loss: 0.5543473958969116\n",
      "Epoch: 976 - loss: 0.47451573610305786 - val loss: 0.5568891167640686\n",
      "Epoch: 977 - loss: 0.4744405746459961 - val loss: 0.5536473989486694\n",
      "Epoch: 978 - loss: 0.4755021035671234 - val loss: 0.5593357682228088\n",
      "Epoch: 979 - loss: 0.47406071424484253 - val loss: 0.5553939342498779\n",
      "Epoch: 980 - loss: 0.4742555320262909 - val loss: 0.5559344291687012\n",
      "Epoch: 981 - loss: 0.47495871782302856 - val loss: 0.5570539236068726\n",
      "Epoch: 982 - loss: 0.47333580255508423 - val loss: 0.5545832514762878\n",
      "Epoch: 983 - loss: 0.4749322235584259 - val loss: 0.5605675578117371\n",
      "Epoch: 984 - loss: 0.4739394783973694 - val loss: 0.5549806356430054\n",
      "Epoch: 985 - loss: 0.47375160455703735 - val loss: 0.5551000237464905\n",
      "Epoch: 986 - loss: 0.4740040600299835 - val loss: 0.5540469288825989\n",
      "Epoch: 987 - loss: 0.4740803837776184 - val loss: 0.5556874871253967\n",
      "Epoch: 988 - loss: 0.4740127921104431 - val loss: 0.5534847378730774\n",
      "Epoch: 989 - loss: 0.47493162751197815 - val loss: 0.5581862926483154\n",
      "Epoch: 990 - loss: 0.47339892387390137 - val loss: 0.5532862544059753\n",
      "Epoch: 991 - loss: 0.47425830364227295 - val loss: 0.5560579895973206\n",
      "Epoch: 992 - loss: 0.4741961658000946 - val loss: 0.5544850826263428\n",
      "Epoch: 993 - loss: 0.47345593571662903 - val loss: 0.5554360151290894\n",
      "Epoch: 994 - loss: 0.473741352558136 - val loss: 0.5552341938018799\n",
      "Epoch: 995 - loss: 0.47325947880744934 - val loss: 0.5528557300567627\n",
      "Epoch: 996 - loss: 0.47449958324432373 - val loss: 0.5572283267974854\n",
      "Epoch: 997 - loss: 0.4750557243824005 - val loss: 0.5566855072975159\n",
      "Epoch: 998 - loss: 0.4735943675041199 - val loss: 0.5543839931488037\n",
      "Epoch: 999 - loss: 0.47314462065696716 - val loss: 0.5551114082336426\n",
      "Epoch: 1000 - loss: 0.47299253940582275 - val loss: 0.5546582341194153\n",
      "0.47739824652671814\n"
     ]
    }
   ],
   "source": [
    "model.use {\n",
    "    it.compile(\n",
    "        optimizer = Adam(0.0001f),\n",
    "        loss = Losses.MAE,\n",
    "        metric = Metrics.MAE,\n",
    "        callback = PrintingCallback(),\n",
    "    )\n",
    "    \n",
    "    it.fit(\n",
    "        dataset = dataset,\n",
    "        validationRate = 0.1,\n",
    "        epochs = 1000,\n",
    "        trainBatchSize = 64,\n",
    "        validationBatchSize = 1024,\n",
    "    )\n",
    "    \n",
    "    val result = it.evaluate(dataset)\n",
    "    println(result.lossValue)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6fd598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "codemirror_mode": "text/x-kotlin",
   "file_extension": ".kt",
   "mimetype": "text/x-kotlin",
   "name": "kotlin",
   "nbconvert_exporter": "",
   "pygments_lexer": "kotlin",
   "version": "1.7.0-dev-3303"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
